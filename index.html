<!doctype html><html lang="en"><head><meta charset="utf-8"><title>Joan Serrà</title><meta property="og:title"content="Joan Serrà"><meta name="twitter:title"content="Joan Serrà"><meta name="description"content="Personal web page"><meta property="og:description"content="Personal web page"><meta name="twitter:description"content="Personal web page"><meta property="og:image"content="https://serrjoa.github.io/images/jserra-circlecrop_small.png"><meta name="twitter:image"content="https://serrjoa.github.io/images/jserra-circlecrop_small.png"><meta name="twitter:card"content="summary_large_image"><link rel="icon"href="https://serrjoa.github.io/images/jserra-circlecrop_small-1.png"><meta name="viewport"content="width=device-width,initial-scale=1"><style>*,::after,::before{box-sizing:border-box;border-width:0;border-style:solid;border-color:currentColor}html{font-size:16px;line-height:1;-webkit-text-size-adjust:100%}ol,ul{padding:0;list-style-type:none}blockquote,body,h1,h2,h3,h4,h5,h6,hr,input,li,ol,p,pre,ul{margin:0}h1,h2,h3,h4,h5,h6,th{font:inherit}a{text-decoration:none}button{display:block;padding:0;border:0;margin:0;background-color:transparent;border-radius:0}:root{--base-font-size-sm:15px;--base-font-size-md:16px;--base-font-size-lg:18px;--base-font-size-xl:20px;--border-radius:0.25rem;--color-bg-1:#fff;--color-bg-2:#f5f5f5;--color-fg-1:#000;--color-fg-2:#303030;--color-fg-3:#7f7f7f;--color-fg-4:#a6a6a6;--color-fg-5:#ccc;--color-accent:#946709;--color-addition-fg:#22863a;--color-addition-bg:#f0fff4;--color-deletion-fg:#b31d28;--color-deletion-bg:#ffeef0;--font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Helvetica,Arial,sans-serif,'Apple Color Emoji','Segoe UI Emoji';--font-family-code:SFMono-Regular,Consolas,'Liberation Mono',Menlo,monospace;--font-weight-regular:normal;--font-weight-bold:bold;--font-size-code:90%;--font-size-sm:0.8rem;--font-size-md:1rem;--line-height-sm:1.25rem;--line-height-md:1.75rem;--size-1:0.25rem;--size-2:0.5rem;--size-3:0.75rem;--size-4:1rem;--size-5:1.25rem;--size-6:1.5rem;--size-7:1.75rem;--size-8:2rem;--size-9:2.25rem;--size-10:2.5rem;--size-12:3rem;--size-16:4rem;--size-20:5rem;--size-24:6rem;--z-index-1:1;--scroll-margin-top:calc(var(--top-bar-height) + 40px);--toc-width:16rem;--top-bar-height:3rem}@media (prefers-color-scheme:dark){:root{color-scheme:dark;--color-bg-1:#000;--color-bg-2:#141414;--color-fg-1:#fff;--color-fg-2:#ccc;--color-fg-3:#7f7f7f;--color-fg-4:#595959;--color-fg-5:#333;--color-accent:#f7eab2;--color-addition-fg:#aff5b4;--color-addition-bg:#033a16;--color-deletion-fg:#ffdcd7;--color-deletion-bg:#67060c}}html{font-size:var(--base-font-size-sm)}body{background-color:var(--color-bg-1);color:var(--color-fg-1);font-family:var(--font-family)}.--menu-visible{overflow:hidden}@media (min-width:640px){html{font-size:var(--base-font-size-md)}.--menu-visible{overflow:visible}}@media (min-width:960px){html{font-size:var(--base-font-size-lg)}}@media (min-width:1280px){html{font-size:var(--base-font-size-xl)}}.content{padding:0 var(--size-4) 0 var(--size-4);font-size:var(--font-size-md);font-weight:var(--font-weight-regular);line-height:var(--line-height-md)}.content__inner{padding:var(--top-bar-height) 0 var(--size-12) 0}.content__inner>:not(pre){overflow-wrap:break-word}.content h1,.content h2,.content h3,.content h4,.content h5,.content h6{font-weight:var(--font-weight-bold)}.content h1{margin-top:var(--size-20);margin-bottom:var(--size-4);font-size:var(--size-8);font-weight:var(--font-weight-bold);letter-spacing:-.0625rem;line-height:var(--size-10)}.content h2{margin-top:var(--size-12);font-size:var(--size-6);letter-spacing:-.03125rem;line-height:var(--size-9)}.content h3{margin-top:var(--size-8);font-size:var(--size-5);letter-spacing:-.03125rem;line-height:var(--size-8)}.content h4{margin-top:var(--size-6);font-size:var(--size-4)}.content h5{margin-top:var(--size-4);font-size:var(--size-3)}.content h6{margin-top:var(--size-4);color:var(--color-fg-2);font-size:var(--size-3);font-style:italic}.content [id]{scroll-margin-top:var(--scroll-margin-top)}.header-link{display:inline-block;padding:0 var(--size-4);color:var(--color-fg-3);font-size:var(--font-size-md);font-weight:var(--font-weight-bold)}.header-link:hover{color:var(--color-fg-2)}.content hr{width:100%;height:1px;border:0;margin-top:var(--size-12);background-color:var(--color-fg-5)}.content a:not(.header-link){color:currentColor;text-decoration:underline;text-decoration-thickness:1px;text-underline-offset:0.1875rem}.content a:not(.header-link):hover{text-decoration:none}.content a:focus-visible,.content a:focus-visible code{background-color:var(--color-fg-1);color:var(--color-bg-1);outline:0}.content__inner div p,.content__inner>blockquote,.content__inner>ol,.content__inner>p,.content__inner>table,.content__inner>ul{margin-top:var(--size-4)}.content blockquote{position:relative;padding:var(--size-2) 0 var(--size-2) var(--size-7);color:var(--color-fg-3)}.content blockquote:before{position:absolute;top:0;bottom:0;left:2px;display:block;width:1px;background-color:var(--color-fg-5);content:''}.content li{position:relative;padding-left:var(--size-7)}.content li:before{position:absolute;top:0;left:0;display:block}.content ul li:before{content:'◦'}.content ol{counter-reset:count}.content ol li{counter-increment:count}.content ol li:before{content:counter(count);font-variant-numeric:tabular-nums}.content table th{color:var(--color-fg-3)}.content img{display:inline-block;max-width:100%}.content code{padding:var(--size-1);background-color:var(--color-bg-2);border-radius:var(--border-radius);color:var(--color-fg-2);font-family:var(--font-family-code);font-size:var(--font-size-code)}.content pre{margin:var(--size-6) 0;color:var(--color-fg-2)}.content pre code{display:block;padding:var(--size-4);overflow-x:auto}.content strong{font-weight:var(--font-weight-bold)}@media (min-width:640px){.content__inner{max-width:70ch;margin:0 auto}}@media (min-width:1280px){.content{margin-left:var(--toc-width)}.content__inner{max-width:66ch}}@media (min-width:1600px){.content__inner{max-width:70ch}.content h1,.content h2,.content h3,.content h4,.content h5,.content h6{position:relative;display:block;padding-left:var(--size-9);margin-left:calc(-1 * var(--size-9))}.header-link{position:absolute;top:0;bottom:0;left:0;display:block;padding:0 var(--size-3)}}@media (hover:hover){.header-link{opacity:0}.content h1:hover .header-link,.content h2:hover .header-link,.content h3:hover .header-link,.content h4:hover .header-link,.content h5:hover .header-link,.content h6:hover .header-link{opacity:1}}.hljs-strong{font-weight:var(--font-weight-bold)}.hljs-emphasis,.hljs-params{font-style:italic}.hljs-comment,.hljs-function,.hljs-keyword,.hljs-meta,.hljs-section,.hljs-selector-class,.hljs-selector-id,.hljs-selector-pseudo,.hljs-variable,.language-html .hljs-tag,.language-json.hljs{color:var(--color-fg-3)}.hljs,.hljs-attr,.hljs-params,.hljs-title,.language-html .hljs-tag .hljs-name,.language-js .xml .hljs-tag .hljs-name,.language-ts .xml .hljs-tag .hljs-name{color:var(--color-fg-2)}.hljs-attribute,.hljs-built_in,.hljs-builtin-name,.hljs-string,.hljs-symbol,.hljs-template-tag,.hljs-template-variable{color:var(--color-fg-1)}.hljs-bullet,.hljs-link,.hljs-literal,.hljs-name,.hljs-number,.hljs-quote,.hljs-regexp,.hljs-selector-attr,.hljs-selector-tag,.language-html .hljs-attr,.language-js .xml .hljs-attr,.language-ts .xml .hljs-attr{color:var(--color-accent)}.hljs-deletion{background-color:var(--color-deletion-bg);color:var(--color-deletion-fg)}.hljs-addition{background-color:var(--color-addition-bg);color:var(--color-addition-fg)}.menu{position:fixed;top:var(--top-bar-height);bottom:0;left:0;display:none;width:100%;padding:var(--size-3) 0;border-right:1px solid var(--color-fg-5);background-color:var(--color-bg-1);font-size:var(--font-size-md);line-height:var(--line-height-md);overflow-y:auto}.--menu-visible .menu{display:block}.menu a{position:relative;display:block;padding:var(--size-1) var(--size-4);color:var(--color-fg-3);overflow-wrap:break-word}.menu li li a{padding-left:var(--size-8)}.menu li li li a{padding-left:var(--size-12)}.menu li li li li a{padding-left:var(--size-16)}.menu li li li li li a{padding-left:var(--size-20)}.menu li li li li li li a{padding-left:var(--size-24)}.menu a:not(.--scroll-spy-active):hover{color:var(--color-fg-2)}.menu a:focus-visible{background-color:var(--color-fg-1);color:var(--color-bg-1);outline:0}.menu a[target='_blank']:after{content:' ↗'}.menu .--scroll-spy-active{color:var(--color-fg-1)}.menu code{font-family:var(--font-family-code);font-size:var(--font-size-code)}@media (min-width:960px){.menu{width:var(--toc-width);font-size:var(--font-size-sm);line-height:var(--line-height-sm)}.--no-toc .menu{display:none}.menu__links{display:none}}@media (min-width:1280px){.menu{display:block;border-right:0}}.top-bar{position:fixed;z-index:var(--z-index-1);top:0;right:0;left:0;display:flex;background-color:var(--color-bg-1);font-size:var(--font-size-md);line-height:var(--top-bar-height);overflow-x:auto;white-space:nowrap}.top-bar:before{position:fixed;top:var(--top-bar-height);right:0;left:0;display:block;height:1px;background-color:var(--color-fg-5);content:'';pointer-events:none}.top-bar a{position:relative;z-index:var(--z-index-1);display:block;padding:0 var(--size-2);color:var(--color-fg-3)}.top-bar a:not(.--scroll-spy-active):hover{color:var(--color-fg-2)}.top-bar a:focus-visible{background-color:var(--color-fg-1);color:var(--color-bg-1);outline:0}.top-bar .--scroll-spy-active{border-bottom:1px solid var(--color-fg-1);color:var(--color-fg-1)}.top-bar__menu-toggle-button{position:relative;display:flex;height:var(--top-bar-height);align-items:center;padding:0 var(--size-4);margin-right:calc(-1 * var(--size-2));color:var(--color-fg-3);cursor:pointer}.top-bar__menu-toggle-button:hover{color:var(--color-fg-2)}.top-bar__menu-toggle-button:focus{outline:0}.top-bar__menu-toggle-button:focus-visible{background-color:var(--color-fg-1);color:var(--color-bg-1);outline:0}.top-bar__menu-toggle-button-close-svg,.top-bar__menu-toggle-button-menu-svg{width:var(--font-size-md);height:var(--font-size-md)}.top-bar__menu-toggle-button-menu-svg{display:block}.--menu-visible .top-bar__menu-toggle-button-menu-svg{display:none}.top-bar__menu-toggle-button-close-svg{display:none}.--menu-visible .top-bar__menu-toggle-button-close-svg{display:block}.top-bar__title{flex-grow:1;padding-left:var(--size-2);color:var(--color-fg-3)}.top-bar .top-bar__title-link{display:inline-block}.top-bar__title-version{display:inline-block;color:var(--color-fg-4)}.top-bar__items{display:none}@media (min-width:960px){.top-bar{font-size:var(--font-size-sm)}.--no-toc .top-bar__menu-toggle-button{display:none}.top-bar__items{display:flex;padding-right:var(--size-2)}.top-bar__items>ul,.top-bar__items>ul li{display:flex}.top-bar__items a[target='_blank']:after{content:' ↗'}}@media (min-width:1280px){.top-bar__menu-toggle-button{display:none}}</style></head><body class=""><main class="content"data-js="content"><div class="content__inner"><p><img src="images/jserra-circlecrop_large.png"alt="Joan Serrà"></p><br><p><span style="font-family:Arial Black; font-size:5.5em;">Joan Serrà</span></p><br><p>Welcome to my personal web page!</p><p>You can also find me on <a href="https://twitter.com/serrjoa"target="_blank"rel="nofollow">Twitter</a>, <a href="http://scholar.google.com/citations?user=sZLj96sAAAAJ"target="_blank"rel="nofollow">Google Scholar</a>, <a href="https://es.linkedin.com/in/joan-serr%C3%A0-b9249018"target="_blank"rel="nofollow">LinkedIn</a>, or <a href="https://github.com/joansj"target="_blank"rel="nofollow">GitHub</a>.</p><h1 id="short-bio">Short bio<a aria-hidden class="header-link"tabindex="-1"href="#short-bio">#</a></h1><span style="color: DarkGrey; line-height: 1.6;"><p>I am a research scientist with <a href="https://www.dolby.com/"target="_blank"rel="nofollow">Dolby Laboratories</a> in Barcelona (since 2019). I work on deep learning for audio analysis and synthesis. I was born in <a href="https://goo.gl/maps/w6cbtgExxNtDVCVq8"target="_blank"rel="nofollow">Riudarenes</a>, Girona (1980). I did my MSc and PhD in machine learning for audio at the <a href="http://mtg.upf.edu/"target="_blank"rel="nofollow">Music Technology Group</a> of <a href="http://www.upf.edu/"target="_blank"rel="nofollow">Universitat Pompeu Fabra</a> (2006-2011). I also did a postdoc in artificial intelligence at <a href="http://iiia.csic.es/"target="_blank"rel="nofollow">IIIA-CSIC</a> (2011-2015). After that, I joined <a href="http://www.tid.es/"target="_blank"rel="nofollow">Telefónica R&#x26;D</a> as a machine learning researcher (2015-2019). I have had research stays at the <a href="http://www.mpipks-dresden.mpg.de/"target="_blank"rel="nofollow">Max Planck Institute for the Physics of Complex Systems</a> (2010) and the <a href="http://www.mpi-inf.mpg.de/"target="_blank"rel="nofollow">Max Planck Institute for Computer Science</a> (2011). I have been involved in several research projects, funded by National and European institutions, and co-authored over 100 publications, many of them highly-cited and/or in top-tier venues. I occasionally act as reviewer or area chair for some of those venues (provided articles are free access/charge), and give talks and lectures on subjects of my interest (lately basically related to deep learning and generative modeling).</p></span><h1 id="publications">Publications<a aria-hidden class="header-link"tabindex="-1"href="#publications">#</a></h1><span style="line-height: 1.4;"><h2 id="ongoing">Ongoing<a aria-hidden class="header-link"tabindex="-1"href="#ongoing">#</a></h2><br><blockquote><p><strong>Upsampling layers for music source separation</strong><br>J. Pons, J. Serrà, S. Pascual, G. Cengarle, D. Arteaga, &#x26; D. Scaini<br>[<a href="https://arxiv.org/abs/2111.11773"target="_blank"rel="nofollow">arxiv</a>] [<a href="http://www.jordipons.me/apps/upsamplers/"target="_blank"rel="nofollow">demo</a>]</p></blockquote><h2 id="recent-2021-2022">Recent (2021-2022)<a aria-hidden class="header-link"tabindex="-1"href="#recent-2021-2022">#</a></h2><br>2022<blockquote><p><strong>Self-supervised perceptual audio encoding by mixing discriminative and reconstructive tasks</strong><br>S. Pascual, J. Serrà, &#x26; J. Pons<br><em>Patent Application</em> No. ES-202230230 (Mar 18, 2022).</p></blockquote><blockquote><p><strong>On loss functions and evaluation metrics for music source separation</strong><br>E. Gusó, J. Pons, S. Pascual, &#x26; J. Serrà<br><em>IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP)</em>. In press.<br>[<a href="https://arxiv.org/abs/2202.07968"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1109/ICASSP43922.2022.9746530"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Assessing algorithmic biases for musical version identification</strong><br>F. Yesiler, M. Miron, J. Serrà, &#x26; E. Gómez<br><em>ACM Int. Conf. on Web Search and Data Mining (WSDM)</em>, pp. 1284-1290. Feb 2022.<br>[<a href="https://arxiv.org/abs/2109.15188"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://dl.acm.org/doi/10.1145/3488560.3498397"target="_blank"rel="nofollow">doi</a>] [<a href="https://github.com/furkanyesiler/vi_bias"target="_blank"rel="nofollow">data,code</a>]</p></blockquote><blockquote><p><strong>Lognormals, power laws and double power laws in the distribution of frequencies of harmonic codewords from classical music</strong><br>M. Serra-Peralta, J. Serrà, &#x26; A. Corral<br><em>Scientific Reports</em> 12, 2615. Feb 2022.<br>[<a href="https://arxiv.org/abs/2110.08200"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1038/s41598-022-06137-3"target="_blank"rel="nofollow">doi</a>] [<a href="https://github.com/MarcSerraPeralta/chromagramer"target="_blank"rel="nofollow">code</a>]</p></blockquote><br>2021<blockquote><p><strong>Audio-based musical version identification: elements and challenges</strong><br>F. Yesiler, G. Doras, R.M. Bittner, C. Tralie, &#x26; J. Serrà<br><em>IEEE Signal Processing Magazine</em> 38(6): 115-136. Nov 2021.<br>[<a href="https://arxiv.org/abs/2109.02472"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1109/MSP.2021.3105941"target="_blank"rel="nofollow">doi</a>] [<a href="https://furkanyesiler.github.io/musical_version_id_spm/"target="_blank"rel="nofollow">web</a>]</p></blockquote><blockquote><p><strong>Adversarial auto-encoding for packet loss concealment</strong><br>S. Pascual, J. Serrà, &#x26; J. Pons<br><em>IEEE Workshop on Appl. of Signal Proc. to Audio and Acoustics (WASPAA)</em>, pp. 71-75. Oct 2021.<br>[<a href="https://arxiv.org/abs/2107.03100"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1109/WASPAA52581.2021.9632730"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Universal speech enhancement with generative neural networks</strong><br>J. Serrà, S. Pascual, &#x26; J. Pons<br><em>Patent Application</em> No. ES-P202130914 (Sep 29, 2021).</p></blockquote><blockquote><p><strong>Heaps' law and vocabulary richness in the history of classical music harmony</strong><br>M. Serra-Peralta, J. Serrà, &#x26; A. Corral<br><em>EPJ Data Science</em> 10: 40. Aug 2021.<br>[<a href="https://arxiv.org/abs/2104.04143"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1140/epjds/s13688-021-00293-8"target="_blank"rel="nofollow">doi</a>] [<a href="https://github.com/MarcSerraPeralta/chromagramer"target="_blank"rel="nofollow">code</a>]</p></blockquote><blockquote><p><strong>Upsampling layers for audio synthesis</strong><br>J. Pons, J. Serrà, S. Pascual, G. Cengarle, D. Arteaga, &#x26; D. Scaini<br><em>Patent Application</em> No. ES-P202130417 (May 7, 2021), US-63/220279 (Jul 9, 2021).</p></blockquote><blockquote><p><strong>On tuning consistent annealed sampling for denoising score matching</strong><br>J. Serrà, S. Pascual, &#x26; J. Pons<br><em>Technical report</em>. Apr 2021.<br>[<a href="https://arxiv.org/abs/2104.03725"target="_blank"rel="nofollow">arxiv</a>]</p></blockquote><blockquote><p><strong>Investigating the efficacy of music version retrieval systems for setlist identification</strong><br>F. Yesiler, E. Molina, J. Serrà, &#x26; E. Gómez<br><em>IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP)</em>, pp. 541-545. Jun 2021.<br>[<a href="https://arxiv.org/abs/2101.02098"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1109/ICASSP39728.2021.9414603"target="_blank"rel="nofollow">doi</a>] [<a href="https://github.com/furkanyesiler/setlist_id"target="_blank"rel="nofollow">data,code</a>]</p></blockquote><blockquote><p><strong>Upsampling artifacts in neural audio synthesis</strong><br>J. Pons, S. Pascual, G. Cengarle, &#x26; J. Serrà<br><em>IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP)</em>, pp. 3005-3009. Jun 2021.<br>[<a href="https://arxiv.org/abs/2010.14356"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1109/ICASSP39728.2021.9414913"target="_blank"rel="nofollow">doi</a>] [<a href="https://github.com/DolbyLaboratories/neural-upsampling-artifacts-audio"target="_blank"rel="nofollow">code</a>]</p></blockquote><blockquote><p><strong>Automatic multitrack mixing with a differentiable mixing console of neural audio effects</strong><br>C.J. Steinmetz, J. Pons, S. Pascual, &#x26; J. Serrà<br><em>IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP)</em>, pp. 71-75. Jun 2021.<br>[<a href="https://arxiv.org/abs/2010.10291"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1109/ICASSP39728.2021.9414364"target="_blank"rel="nofollow">doi</a>] [<a href="https://csteinmetz1.github.io/dmc-icassp2021/"target="_blank"rel="nofollow">samples,scripts</a>]</p></blockquote><blockquote><p><strong>SESQA: semi-supervised learning for speech quality assessment</strong><br>J. Serrà, J. Pons, &#x26; S. Pascual<br><em>IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP)</em>, pp. 381-385. Jun 2021.<br>[<a href="https://arxiv.org/abs/2010.00368"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1109/ICASSP39728.2021.9414052"target="_blank"rel="nofollow">doi</a>]</p></blockquote><h2 id="past-2011-2020">Past (2011-2020)<a aria-hidden class="header-link"tabindex="-1"href="#past-2011-2020">#</a></h2><br>2020<blockquote><p><strong>Real-time packet loss concealment using deep generative networks</strong><br>S. Pascual, J. Serrà, &#x26; J. Pons<br><em>Patent Application</em> No. ES-P202031040 (Oct 15, 2020), US-63/195831 (Jun 2, 2021).</p></blockquote><blockquote><p><strong>Less is more: faster and better music version identification with embedding distillation</strong><br>F. Yesiler, J. Serrà, &#x26; E. Gómez<br><em>Int. Soc. for Music Information Retrieval Conf. (ISMIR)</em>. Oct 2020.<br>[<a href="https://arxiv.org/abs/2010.03284"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://program.ismir2020.net/poster_6-15.html"target="_blank"rel="nofollow">ismir</a>]</p></blockquote><blockquote><p><strong>Combining musical features for cover detection</strong><br>G. Doras, F. Yesiler, J. Serrà, E. Gómez, &#x26; G. Peeters<br><em>Int. Soc. for Music Information Retrieval Conf. (ISMIR)</em>. Oct 2020.<br>[<a href="https://doi.org/10.5281/zenodo.4245424"target="_blank"rel="nofollow">zenodo</a>] [<a href="https://program.ismir2020.net/poster_2-15.html"target="_blank"rel="nofollow">ismir</a>]</p></blockquote><blockquote><p><strong>Experience: advanced network operations in (un-)connected remote communities</strong><br>D. Perino, X. Yang, J. Serrà, A. Lutu, &#x26; I. Leontiadis<br><em>ACM Int. Conf. on Mobile Computing and Networking (MobiCom)</em>, num. 1. Sep 2020.<br>[<a href="https://dl.acm.org/doi/abs/10.1145/3372224.3380893"target="_blank"rel="nofollow">acm</a>] [<a href="https://doi.org/10.1145/3372224.3380893"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Method for learning an audio quality metric combining labeled and unlabeled data</strong><br>J. Serrà, J. Pons, &#x26; S. Pascual<br><em>Patent Application</em> No. ES-P202030605 (Jun 22, 2020), US-63/072787 (Aug 31, 2020), EP2021/066786 (Jun 21, 2021).</p></blockquote><blockquote><p><strong>System for automated multitrack mixing in the waveform domain with a learned differentiable mixing console and controller network</strong><br>C.J. Steinmetz &#x26; J. Serrà.<br><em>Patent Application</em> No. ES-P202030604 (Jun 22, 2020), US-63/072762 (Aug 31, 2020), EP2021/066206 (Jun 16, 2021).</p></blockquote><blockquote><p><strong>Accurate and scalable version identification using musically-motivated embeddings</strong><br>F. Yesiler, J. Serrà, &#x26; E. Gómez<br><em>IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP)</em>, pp. 21-25. May 2020.<br>[<a href="http://arxiv.org/abs/1910.12551"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1109/ICASSP40776.2020.9053793"target="_blank"rel="nofollow">doi</a>] [<a href="https://github.com/furkanyesiler/move"target="_blank"rel="nofollow">code,model,eval</a>]</p></blockquote><blockquote><p><strong>Input complexity and out-of-distribution detection with likelihood-based generative models</strong><br>J. Serrà, D. Álvarez, V. Gómez, O. Slizovskaia, J.F. Núñez, &#x26; J. Luque<br><em>Int. Conf. on Learning Representations (ICLR)</em>. Apr 2020.<br>[<a href="https://arxiv.org/abs/1909.11480"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://openreview.net/forum?id=SyxIWpVYvr"target="_blank"rel="nofollow">openreview</a>] [<a href="https://iclr.cc/virtual_2020/poster_SyxIWpVYvr.html"target="_blank"rel="nofollow">video</a>]</p></blockquote><br>2019<blockquote><p><strong>Blow: a single-scale hyperconditioned flow for non-parallel raw-audio voice conversion</strong><br>J. Serrà, S. Pascual, &#x26; C. Segura<br><em>Advances in Neural Information Processing Systems (NeurIPS)</em> 32: 6790-6800. Dec 2019.<br>[<a href="https://arxiv.org/abs/1906.00794"target="_blank"rel="nofollow">arxiv</a> [<a href="https://papers.nips.cc/paper/8904-blow-a-single-scale-hyperconditioned-flow-for-non-parallel-raw-audio-voice-conversion"target="_blank"rel="nofollow">neurips</a>] [<a href="https://github.com/joansj/blow"target="_blank"rel="nofollow">code</a>] [<a href="https://blowconversions.github.io/"target="_blank"rel="nofollow">examples</a>]</p></blockquote><blockquote><p><strong>Towards generalized speech enhancement with generative adversarial networks</strong><br>S. Pascual, J. Serrà, &#x26; A. Bonafonte<br><em>Conf. of the Int. Speech Communication Assoc. (INTERSPEECH)</em>, pp. 161-165. Sep 2019.<br>[<a href="https://arxiv.org/abs/1904.03418"target="_blank"rel="nofollow">arxiv</a>] [<a href="http://dx.doi.org/10.21437/Interspeech.2019-2688"target="_blank"rel="nofollow">doi</a>] [<a href="https://github.com/santi-pdp/segan_pytorch"target="_blank"rel="nofollow">code</a>] [<a href="http://veu.talp.cat/gsegan/"target="_blank"rel="nofollow">examples</a>]</p></blockquote><blockquote><p><strong>Learning problem-agnostic speech representations from multiple self-supervised tasks</strong><br>S. Pascual, M. Ravanelli, J. Serrà, A. Bonafonte, &#x26; Y. Bengio<br><em>Conf. of the Int. Speech Communication Assoc. (INTERSPEECH)</em>, pp. 1791-1795. Sep 2019.<br>[<a href="https://arxiv.org/abs/1904.03416"target="_blank"rel="nofollow">arxiv</a>] [<a href="http://dx.doi.org/10.21437/Interspeech.2019-2605"target="_blank"rel="nofollow">doi</a>] [<a href="https://github.com/santi-pdp/pase"target="_blank"rel="nofollow">code,model</a>]</p></blockquote><blockquote><p><strong>Time-domain speech enhancement using generative adversarial networks</strong><br>S. Pascual, J. Serrà, &#x26; A. Bonafonte<br><em>Speech Communication</em> 114: 10-21. Sep 2019.<br>[<a href="https://doi.org/10.1016/j.specom.2019.09.001"target="_blank"rel="nofollow">doi</a>] [<a href="https://github.com/santi-pdp/segan_pytorch"target="_blank"rel="nofollow">code</a>] [<a href="http://veu.talp.cat/seganp"target="_blank"rel="nofollow">examples1</a>,<a href="http://veu.talp.cat/whispersegan"target="_blank"rel="nofollow">examples2</a>]</p></blockquote><blockquote><p><strong>Exploring efficient neural architectures for linguistic-acoustic mapping in text-to-speech</strong><br>S. Pascual, J. Serrà, &#x26; A. Bonafonte<br><em>Applied Sciences</em> 9(16): 3391. Aug 2019.<br>[<a href="https://doi.org/10.3390/app9163391"target="_blank"rel="nofollow">doi</a>] [<a href="https://github.com/santi-pdp/musa_tts"target="_blank"rel="nofollow">code</a>]</p></blockquote><blockquote><p><strong>Training neural audio classifiers with few data</strong><br>J. Pons, J. Serrà, &#x26; X. Serra<br><em>IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 16-20. May 2019.<br>[​<a href="https://arxiv.org/abs/1810.10274"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1109/ICASSP.2019.8682591"target="_blank"rel="nofollow">doi</a>] [<a href="https://github.com/jordipons/neural-classifiers-with-few-audio/"target="_blank"rel="nofollow">code</a>]</p></blockquote><br>2018<blockquote><p><strong>When the state of the art is ahead of the state of understanding: unintuitive properties of deep neural networks</strong><br>J. Serrà<br><em>Métode Science Studies Journal</em> 99: 13-17. Dec 2018.<br>[<a href="https://ojs.uv.es/index.php/Metode/article/view/11035"target="_blank"rel="nofollow">uv</a>] [<a href="https://doi.org/10.7203/metode.9.11035"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>There goes Wally: anonymously sharing your location gives you away</strong><br>A. Pyrgelis, N. Kourtellis, I. Leontiadis, J. Serrà, &#x26; C. Soriente<br><em>IEEE Int. Conf. on Big Data (BigData)</em>, pp. 1218-1227. Dec 2018.<br>[​<a href="https://arxiv.org/abs/1806.02701"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1109/BigData.2018.8622184"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Real non-volume preserving voice conversion</strong><br>S. Pascual, J. Serrà, &#x26; A. Bonafonte<br><em>LXAI Research Workshop (NeurIPS-LXAI)</em>. Dec 2018.<br>[<a href="http://veu.talp.cat/santi_slides/rnvpvc.pdf"target="_blank"rel="nofollow">talp</a>] [​<a href="http://www.latinxinai.org/nips-2018"target="_blank"rel="nofollow">lxai</a>]</p></blockquote><blockquote><p><strong>Self-attention linguistic-acoustic decoder</strong><br>S. Pascual, A. Bonafonte, &#x26; J. Serrà<br><em>IberSPEECH Conf.</em>, pp. 152-156. Nov 2018.<br>[<a href="https://arxiv.org/abs/1808.10678"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://www.isca-speech.org/archive/IberSPEECH_2018/abstracts/IberS18_O4-5_Pascual.html"target="_blank"rel="nofollow">isca</a>]</p></blockquote><blockquote><p><strong>Whispered-to-voiced alaryngeal speech conversion with generative adversarial networks</strong><br>S. Pascual, A. Bonafonte, J. Serrà, &#x26; J.A. Gonzalez<br><em>IberSPEECH Conf.</em>, pp. 117-121. Nov 2018.<br>[<a href="https://arxiv.org/abs/1808.10687"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://www.isca-speech.org/archive/IberSPEECH_2018/abstracts/IberS18_O3-3_Pascual.html"target="_blank"rel="nofollow">isca</a>] [<a href="https://github.com/santi-pdp/segan_pytorch"target="_blank"rel="nofollow">code</a>]</p></blockquote><blockquote><p><strong>Towards a universal neural network encoder for time series</strong><br>J. Serrà, S. Pascual, &#x26; A. Karatzoglou<br><em>Int. Conf. of the Catalan Association for Artificial Intelligence (CCIA)</em>, Frontiers in Artificial Intelligence and Applications 308, pp. 120-129. Oct 2018.<br>[<a href="https://arxiv.org/abs/1805.03908"target="_blank"rel="nofollow">arxiv</a>] [<a href="http://ebooks.iospress.nl/volumearticle/50398"target="_blank"rel="nofollow">ios</a>]</p></blockquote><blockquote><p><strong>MobInsight: a framework using semantic neighborhood features for localized interpretations of urban mobility</strong><br>S. Park, J. Serrà, E. Frias-Martinez, &#x26; N. Oliver<br><em>ACM Trans. on Interactive Intelligent Systems</em> 8(3): 23. Jul 2018.<br>[<a href="https://arxiv.org/abs/1709.10299"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1145/3158433"target="_blank"rel="nofollow">doi</a>] [<a href="http://34.249.109.198/MobilitySemantics/html/viz.html"target="_blank"rel="nofollow">demo</a>]</p></blockquote><blockquote><p><strong>Overcoming catastrophic forgetting with hard attention to the task</strong><br>J. Serrà, D. Surís, M. Miron, &#x26; A. Karatzoglou<br><em>Int. Conf. on Machine Learning (ICML)</em> 80: 4555-4564. Jul 2018.<br>[<a href="https://arxiv.org/abs/1801.01423"target="_blank"rel="nofollow">arxiv</a>] [<a href="http://proceedings.mlr.press/v80/serra18a.html"target="_blank"rel="nofollow">pmlr</a>] [<a href="https://github.com/joansj/hat"target="_blank"rel="nofollow">code</a>]</p></blockquote><blockquote><p><strong>Empirical evidence on daily cash flow time series and its implications for forecasting</strong><br>F. Salas-Molina, J.A. Rodríguez-Aguilar, J. Serrà, M. Guillen, &#x26; F.J. Martín<br><em>Statistics and Operations Research Transactions</em> 42(1): 73-98. Jun 2018.<br>[<a href="http://arxiv.org/abs/1611.04941"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.2436/20.8080.02.70"target="_blank"rel="nofollow">doi</a>] [<a href="http://www.iiia.csic.es/~jar/54datasets3.csv"target="_blank"rel="nofollow">data</a>]</p></blockquote><blockquote><p><strong>Language and noise transfer in speech enhancement generative adversarial network</strong><br>S. Pascual, M. Park, J. Serrà, A. Bonafonte, &#x26; K.-H. Ahn<br><em>IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 5019-5023. Apr 2018.<br>[<a href="https://arxiv.org/abs/1712.06340"target="_blank"rel="nofollow">arxiv</a>]﻿ [<a href="https://doi.org/10.1109/ICASSP.2018.8462322"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Unintuitive properties of deep neural networks</strong><br>J. Serrà<br><em>Proc. of the EC Workshop on Human Behaviour and Machine Intelligence (HUMAINT)</em>, pp. 11-12. Mar 2018.<br>[<a href="https://ec.europa.eu/jrc/communities/community/humaint/document/assessing-impact-machine-intelligence-human-behaviour-interdisciplinary"target="_blank"rel="nofollow">ec</a>]</p></blockquote><br>2017<blockquote><p><strong>Continual prediction of notification attendance with classical and deep network approaches</strong><br>K. Katevas, I. Leontiadis, M. Pielot, &#x26; J. Serrà<br><em>Technical report</em>. Dec 2017.<br>[<a href="https://arxiv.org/abs/1712.07120"target="_blank"rel="nofollow">arXiv</a>]</p></blockquote><blockquote><p><strong>Beyond interruptibility: predicting opportune moments to engage mobile phone users</strong><br>M. Pielot, B. Cardoso, K. Katevas, J. Serrà, A. Matic, &#x26; N. Oliver<br><em>ACM Interactive, Mobile, Wearable and Ubiquitous Technologies</em> 1(3): 91. Sep 2017. Presented at UbiComp 2017.<br>[<a href="http://pielot.org/2017/08/beyond-interruptibility-predicting-opportune-moments-to-engage-mobile-phone-users/"target="_blank"rel="nofollow">pielot</a>] [<a href="https://doi.org/10.1145/3130956"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Getting deep recommenders fit: Bloom embeddings for sparse binary input/output networks</strong><br>J. Serrà &#x26; A. Karatzoglou<br><em>ACM Conf. on Recommender Systems (RECSYS)</em>, pp. 279-287. Aug 2017.<br>[<a href="https://arxiv.org/abs/1706.03993"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1145/3109859.3109876"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>SEGAN: speech enhancement generative adversarial network</strong><br>S. Pascual, A. Bonafonte, &#x26; J. Serrà<br><em>Conf. of the Int. Speech Communication Assoc. (INTERSPEECH)</em>, pp. 3642-3646. Aug 2017.<br>[<a href="https://arxiv.org/abs/1703.09452"target="_blank"rel="nofollow">arxiv</a>] [<a href="http://dx.doi.org/10.21437/Interspeech.2017-1428"target="_blank"rel="nofollow">doi</a>] [<a href="https://github.com/santi-pdp/segan"target="_blank"rel="nofollow">code</a>] [<a href="http://veu.talp.cat/segan/"target="_blank"rel="nofollow">examples</a>]</p></blockquote><blockquote><p><strong>Class-based prediction errors to detect hate speech with out-of-vocabulary words</strong><br>J. Serrà, I. Leontiadis, D. Spathis, G. Stringhini, J. Blackburn, &#x26; A. Vakali<br><em>Workshop on Abusive Language Online (ALW), Conf. of the Association for Computational Linguistics (ACL)</em>, pp. 36-40. Aug 2017.<br>[<a href="https://openreview.net/forum?id=SyhSiq7te"target="_blank"rel="nofollow">openreview</a>] [<a href="http://www.aclweb.org/anthology/W17-3005"target="_blank"rel="nofollow">acl</a>]</p></blockquote><blockquote><p><strong>Practical processing of mobile sensor data for continual deep learning predictions</strong><br>K. Katevas, I. Leontiadis, M. Pielot, &#x26; J. Serrà<br><em>Workshop on Deep Learning for Mobile Systems and Applications (DeepMobile), ACM Int. Conf. on Mobile Systems, Applications and Services (MOBISYS)</em>, pp. 19-24. Jun 2017.<br>[<a href="https://arxiv.org/abs/1705.06224"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1145/3089801.3089802"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Compact embedding of binary-coded inputs and outputs using Bloom filters</strong><br>J. Serrà &#x26; A. Karatzoglou<br><em>Int. Conf. on Learning Representations (ICLR) Workshop</em>. Apr 2017.<br>[<a href="https://openreview.net/forum?id=rySCp-1Yg"target="_blank"rel="nofollow">openreview</a>]</p></blockquote><blockquote><p><strong>The good, the bad, and the KPIs: how to combine performance metrics to better capture under-performing sectors in mobile networks</strong><br>I. Leontiadis, J. Serrà, A. Finamore, G. Dimopoulos, &#x26; K. Papagiannaki<br><em>IEEE Int. Conf. on Data Engineering (ICDE)</em>, pp. 297-308. Apr 2017.<br>[<a href="http://ieeexplore.ieee.org/document/7929986/"target="_blank"rel="nofollow">ieee</a>] [<a href="https://doi.org/10.1109/ICDE.2017.89"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Hot or not? Forecasting cellular network hot spots using sector performance indicators</strong><br>J. Serrà, I. Leontiadis, A. Karatzoglou, &#x26; K. Papagiannaki<br><em>IEEE Int. Conf. on Data Engineering (ICDE)</em>, pp. 259-270. Apr 2017.<br>[<a href="http://arxiv.org/abs/1704.05249"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1109/ICDE.2017.85"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Empowering cash managers to achieve cost savings by improving predictive accuracy</strong><br>F. Salas-Molina, F.J. Martín, J.A. Rodríguez-Aguilar, J. Serrà, &#x26; J.L. Arcos<br><em>International Journal of Forecasting</em> 23(2): 403-415. Apr 2017.<br>[<a href="http://arxiv.org/abs/1605.04219"target="_blank"rel="nofollow">arxiv</a>] [<a href="http://dx.doi.org/10.1016/j.ijforecast.2016.11.002"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Performance metrics using KPI combinations to better capture underperforming sectors in mobile networks</strong><br>I. Leontiadis, J. Serrà, &#x26; A. Finamore<br><em>Patent</em> EP17382164.6, filed on 31/03/2017.</p></blockquote><blockquote><p><strong>Forecast of cellular network hot spots using sector performance indicators</strong><br>J. Serrà &#x26; I. Leontiadis<br><em>Patent</em> EP17382163.8, filed on 31/03/2017.</p></blockquote><blockquote><p><strong>Effect of acoustic conditions on algorithms to detect Parkinson's disease from speech</strong><br>J.C. Vásquez-Correa, J. Serrà, J.R. Orozco-Arroyave, J.F. Vargas-Bonilla, &#x26; E. Nöth<br><em>IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 5065-5069. Mar 2017.<br>[<a href="http://ieeexplore.ieee.org/document/7953121/"target="_blank"rel="nofollow">ieee</a>] [<a href="https://doi.org/10.1109/ICASSP.2017.7953121"target="_blank"rel="nofollow">doi</a>]</p></blockquote><br>2016<blockquote><p><strong>A genetic algorithm to discover flexible motifs with support</strong><br>J. Serrà, A. Matic, J.L. Arcos, &#x26; A. Karatzoglou<br><em>Workshop on Spatial and Spatiotemporal Data Mining (SSTDM), IEEE Int. Conf. on Data Mining (ICDM)</em>, pp. 1153-1158. Dec 2016.<br>[<a href="http://arxiv.org/abs/1511.04986"target="_blank"rel="nofollow">arxiv</a>] [<a href="https://doi.org/10.1109/ICDMW.2016.0166"target="_blank"rel="nofollow">doi</a>] [<a href="https://github.com/joansj/genmotif"target="_blank"rel="nofollow">code</a>]</p></blockquote><blockquote><p><strong>Time-delayed melody surfaces for raga recognition</strong><br>S. Gulati, J. Serrà, K.K. Ganguli, S. Senturk, &#x26; X. Serra<br><em>Int. Soc. for Music Information Retrieval Conf. (ISMIR)</em>, pp. 751-757. Aug 2016.<br>[<a href="http://mtg.upf.edu/node/3487"target="_blank"rel="nofollow">mtg</a>] [<a href="https://wp.nyu.edu/ismir2016/wp-content/uploads/sites/2294/2016/07/030_Paper.pdf"target="_blank"rel="nofollow">ismir</a>]</p></blockquote><blockquote><p><strong>Ranking and significance of variable-length similarity-based time series motifs</strong><br>J. Serrà, I. Serra, A. Corral, &#x26; J.L. Arcos<br><em>Expert Systems with Applications</em> 55: 452-460. Aug 2016.<br>[<a href="http://arxiv.org/abs/1503.01883"target="_blank"rel="nofollow">arxiv</a>] [<a href="http://dx.doi.org/10.1016/j.eswa.2016.02.026"target="_blank"rel="nofollow">doi</a>] [<a href="http://www.iiia.csic.es/~jserra/motifranking/"target="_blank"rel="nofollow">code</a>]</p></blockquote><blockquote><p><strong>What makes a city vital and safe: Bogotá case study</strong><br>A. Bogomolov, A. Clavijo, M. De Nadai, R. Lara Molina, B. Lepri, E. Letouzé, N. Oliver, G. Pestre, J. Serrà, N. Shoup, &#x26; A. Ramirez Suarez<br><em>Annual Bank Conf. on Development Economics (ABCDE): Data and Development Economics, session 2D: Crime, Civil Wars, and Hotspots</em>. Jun 2016.<br>[<a href="http://www.worldbank.org/en/events/2015/11/10/annual-bank-conference-on-development-economics-2016-data-and-development"target="_blank"rel="nofollow">abcde1</a>] [<a href="http://pubdocs.worldbank.org/pubdocs/publicdoc/2016/6/211351466184583762/What-makes-a-city-vital-and-safe.pdf"target="_blank"rel="nofollow">abcde2</a>]</p></blockquote><blockquote><p><strong>Phrase-based raga recognition using vector space modeling</strong><br>S. Gulati, J. Serrà, V. Ishwar, S. Senturk, &#x26; X. Serra<br><em>IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP)</em>, pp. 66-70. Mar 2016.<br>[<a href="http://www.mtg.upf.edu/node/3425"target="_blank"rel="nofollow">mtg</a>] [<a href="http://dx.doi.org/10.1109/ICASSP.2016.7471638"target="_blank"rel="nofollow">doi</a>] [<a href="http://compmusic.upf.edu/node/278"target="_blank"rel="nofollow">code,data</a>]</p></blockquote><blockquote><p><strong>Discovering raga motifs by characterizing communities in networks of melodic patterns</strong><br>S. Gulati, J. Serrà, V. Ishwar, &#x26; X. Serra<br><em>IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP)</em>, pp. 286-290. Mar 2016.<br>[<a href="http://www.mtg.upf.edu/node/3424"target="_blank"rel="nofollow">mtg</a>] [<a href="http://dx.doi.org/10.1109/ICASSP.2016.7471682"target="_blank"rel="nofollow">doi</a>] [<a href="http://compmusic.upf.edu/node/277"target="_blank"rel="nofollow">code,data</a>]</p></blockquote><blockquote><p><strong>Particle swarm optimization for time series motif discovery</strong><br>J. Serrà &#x26; J.L. Arcos<br><em>Knowledge-Based Systems</em> 92: 127-137. Jan 2016.<br>[<a href="http://arxiv.org/abs/1501.07399"target="_blank"rel="nofollow">arxiv</a>] [<a href="http://dx.doi.org/10.1016/j.knosys.2015.10.021"target="_blank"rel="nofollow">doi</a>] [<a href="http://www.iiia.csic.es/~jserra/swarmmotif/"target="_blank"rel="nofollow">code</a>]</p></blockquote><br>2015<blockquote><p><strong>Improving melodic similarity in Indian art music using culture specific melodic characteristics</strong><br>S. Gulati, J. Serrà, &#x26; X. Serra<br><em>Int. Soc. for Music Information Retrieval Conf. (ISMIR)</em>, pp. 680-686. Oct 2015.<br>[<a href="http://www.mtg.upf.edu/node/3318"target="_blank"rel="nofollow">mtg</a>] [<a href="http://ismir2015.uma.es/articles/69_Paper.pdf"target="_blank"rel="nofollow">ismir</a>]</p></blockquote><blockquote><p><strong>Analysis of the impact of a tag recommendation system in a real-world folksonomy</strong><br>F. Font, J. Serrà, &#x26; X. Serra<br><em>ACM Trans. on Intelligent Systems and Technology</em> 7(1): 6. Oct 2015.<br>[<a href="http://www.iiia.csic.es/en/publications/analysis-impact-tag-recommendation-system-real-world-folksonomy"target="_blank"rel="nofollow">iiia</a>] [<a href="http://dx.doi.org/10.1145/2743026"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Zipf-like distributions in language and music</strong><br>I. Moreno, F. Font-Clos, J. Serrà, &#x26; A. Corral<br><em>Complexitat.cat Workshop</em>. May 2015.<br>[<a href="http://jornada.complexitat.cat/"target="_blank"rel="nofollow">complexitat.cat</a>]</p></blockquote><blockquote><p><strong>An evaluation of methodologies for melodic similarity in audio recordings of Indian art music</strong><br>S. Gulati, J. Serrà, &#x26; X. Serra<br><em>IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP)</em>, pp. 678-682. Apr 2015.<br>[<a href="http://www.iiia.csic.es/en/publications/evaluation-methodologies-melodic-similarity-audio-recordings-indian-art-music"target="_blank"rel="nofollow">iiia</a>] [<a href="http://dx.doi.org/10.1109/ICASSP.2015.7178055"target="_blank"rel="nofollow">doi</a>]</p></blockquote><br>2014<blockquote><p><strong>Mining melodic patterns in large audio collections of Indian art music</strong><br>S. Gulati, J. Serrà, V. Ishwar, &#x26; X. Serra<br><em>Int. Conf. on Signal Image Technology and Internet Based Systems (SITIS)</em>, pp. 264-271. Nov 2014.<br>[<a href="http://www.iiia.csic.es/en/publications/mining-melodic-patterns-large-audio-collections-indian-art-music"target="_blank"rel="nofollow">iiia</a>] [<a href="http://dx.doi.org/10.1109/SITIS.2014.73"target="_blank"rel="nofollow">doi</a>] [<a href="http://compmusic.upf.edu/node/210"target="_blank"rel="nofollow">code,data</a>]</p></blockquote><blockquote><p><strong>Melodic pattern extraction in large collections of music recordings using time series mining techniques</strong><br>S. Gulati, J. Serrà, V. Ishwar, &#x26; X. Serra<br>Demo at the <em>Int. Soc. for Music Information Retrieval Conf. (ISMIR)</em>. Oct 2014.<br>[<a href="http://www.iiia.csic.es/en/publications/melodic-pattern-extraction-large-collections-music-recordings-using-time-series-mining-0"target="_blank"rel="nofollow">iiia</a>] [<a href="http://www.terasoft.com.tw/conf/ismir2014/LBD%5CLBD22.pdf"target="_blank"rel="nofollow">ismir</a>]</p></blockquote><blockquote><p><strong>An empirical evaluation of similarity measures for time series classification</strong><br>J. Serrà &#x26; J.L. Arcos<br><em>Knowledge-Based Systems</em> 67: 305-314. Sep 2014.<br>[<a href="http://www.iiia.csic.es/en/publications/empirical-evaluation-similarity-measures-time-series-classification"target="_blank"rel="nofollow">iiia</a>] [<a href="http://dx.doi.org/10.1016/j.knosys.2014.04.035"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Landmark detection in Hindustani music melodies</strong> S. Gulati, J. Serrà, K.K. Ganguli, &#x26; X. Serra<br><em>Int. Computer Music Conf. / Sound and Music Computing Conf. (ICMC/SMC)</em>, vol. 2, pp. 1062-1068. Sep 2014.<br>[<a href="http://www.iiia.csic.es/en/publications/landmark-detection-hindustani-music-melodies"target="_blank"rel="nofollow">iiia</a>] [<a href="http://www.icmc14-smc14.net/program/conference-program/scientific_program.html"target="_blank"rel="nofollow">icmc,smc</a>] [<a href="http://www.freesound.org/people/sankalp/packs/12292/"target="_blank"rel="nofollow">data</a>]</p></blockquote><blockquote><p><strong>Class-based tag recommendation and user-based evaluation in online audio clip sharing</strong><br>F. Font, J. Serrà, &#x26; X. Serra<br><em>Knowledge-Based Systems</em> 67: 131-142. Sep 2014.<br>[<a href="http://www.iiia.csic.es/en/publications/class-based-tag-recommendation-and-user-based-evaluation-online-audio-clip-sharing"target="_blank"rel="nofollow">iiia</a>] [<a href="http://dx.doi.org/10.1016/j.knosys.2014.06.003"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Unsupervised music structure annotation by time series structure features and segment similarity</strong><br>J. Serrà, M. Müller, P. Grosche, &#x26; J.L. Arcos<br><em>IEEE Trans. on Multimedia, Special Issue on Music Data Mining</em> 16(5): 1229-1240. Aug 2014.<br>[<a href="http://www.iiia.csic.es/en/publications/unsupervised-music-structure-annotation-time-series-structure-features-and-segment-simi"target="_blank"rel="nofollow">iiia</a>] [<a href="http://dx.doi.org/10.1109/TMM.2014.2310701"target="_blank"rel="nofollow">doi</a>] [<a href="http://www.iiia.csic.es/~jserra/downloads/2012_SerraMGA_MIREX-Structure.tar.gz"target="_blank"rel="nofollow">code</a>]</p></blockquote><blockquote><p><strong>Intonation analysis of ragas in Carnatic music</strong><br>G.K. Koduri, V. Ishwar, J. Serrà, &#x26; X. Serra<br><em>Journal of New Music Research, Special Issue on Computational Approaches to the Art Music Traditions of India and Turkey</em> 43(1): 72-93. Mar 2014.<br>[<a href="http://www.iiia.csic.es/en/publications/intonation-analysis-ragas-carnatic-music"target="_blank"rel="nofollow">iiia</a>] [<a href="http://dx.doi.org/10.1080/09298215.2013.866145"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Audio clip classification using social tags and the effect of tag expansion</strong><br>F. Font, J. Serrà, &#x26; X. Serra<br><em>AES Int. Conf. on Semantic Audio</em>, paper num. 26. Jan 2014.<br>[<a href="http://www.iiia.csic.es/en/publications/audio-clip-classification-using-social-tags-and-effect-tag-expansion"target="_blank"rel="nofollow">iiia</a>] [<a href="http://www.aes.org/e-lib/browse.cfm?elib=17091"target="_blank"rel="nofollow">aes</a>]</p></blockquote><br>2013<blockquote><p><strong>Folksonomy-based tag recommendation for collaborative tagging systems</strong><br>F. Font, J. Serrà, &#x26; X. Serra<br><em>Int. Journal on Semantic Web and Information Systems</em> 9(2): 1-30. Nov 2013.<br>[<a href="http://www.iiia.csic.es/en/publications/folksonomy-based-tag-recommendation-collaborative-tagging-systems"target="_blank"rel="nofollow">iiia</a>] [<a href="http://dx.doi.org/10.4018/jswis.2013040101"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>What can we learn from massive music archives?</strong><br>J. Serrà<br><em>Dagstuhl Seminar 13451: Computational Audio Analysis</em>. M. Müller, S. Narayanan, and B. Schuller, eds. Wadern, Germany. Nov 2013.<br>[<a href="http://www.iiia.csic.es/es/publications/what-can-we-learn-massive-music-archives"target="_blank"rel="nofollow">iiia</a>] [<a href="http://www.dagstuhl.de/en/program/calendar/semhp/?semnr=13451"target="_blank"rel="nofollow">dagstuhl</a>]</p></blockquote><blockquote><p><strong>Learning of units and knowledge representation</strong><br>F. Metze, X. Anguera, S. Ewert, J. Gemmeke, D. Kolossa, E. Mower Provost, B. Schuller, &#x26; J. Serrà<br><em>Dagstuhl Seminar 13451: Computational Audio Analysis</em>. M. Müller, S. Narayanan, and B. Schuller, eds. Wadern, Germany. Nov 2013.<br>[<a href="http://www.iiia.csic.es/en/publications/learning-units-and-knowledge-representation"target="_blank"rel="nofollow">iiia</a>] [<a href="http://drops.dagstuhl.de/opus/volltexte/2014/4434/pdf/dagrep_v003_i011_p001_s13451.pdf#page=13"target="_blank"rel="nofollow">dagstuhl</a>]</p></blockquote><blockquote><p><strong>Source separation</strong><br>C. Uhle, J. Driedger, B. Edler, S. Ewert, F. Graf, G. Kubin, M. Müller, N. Ono, B. Pardo, &#x26; J. Serrà<br><em>Dagstuhl Seminar 13451: Computational Audio Analysis</em>. M. Müller, S. Narayanan, and B. Schuller, eds. Wadern, Germany. Nov 2013.<br>[<a href="http://www.iiia.csic.es/en/publications/source-separation"target="_blank"rel="nofollow">iiia</a>] [<a href="http://drops.dagstuhl.de/opus/volltexte/2014/4434/pdf/dagrep_v003_i011_p001_s13451.pdf#page=15"target="_blank"rel="nofollow">dagstuhl</a>]</p></blockquote><blockquote><p><strong>Towards cover group thumbnailing</strong><br>P. Grosche, M. Müller, &#x26; J. Serrà<br><em>ACM Int. Conf. on Multimedia (ACM-MM)</em>, pp. 613-616. Oct 2013.<br>[<a href="http://www.iiia.csic.es/en/publications/towards-cover-group-thumbnailing"target="_blank"rel="nofollow">iiia</a>] [<a href="http://dx.doi.org/10.1145/2502081.2502161"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Sample identification in hip-hop music</strong><br>J. Van Balen, J. Serrà, &#x26; M. Haro<br><em>From Sounds to Music and Emotions</em>, M. Aramaki, M. Barthet, R. Kronland-Martinet, and S. Ystad eds., Lecture Notes in Computer Science, vol. 7900, ch. 5, pp. 301-312. Sep 2013.<br>[<a href="http://www.iiia.csic.es/en/publications/sample-identification-hip-hop-music"target="_blank"rel="nofollow">iiia</a>] [<a href="http://dx.doi.org/10.1007/978-3-642-41248-6_16"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Note onset deviations as musical piece signatures</strong> J. Serrà, T.H. Özaslan, &#x26; J.L. Arcos<br><em>PLoS ONE</em> 8(7): e69268. Jul 2013.<br>[<a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0069268"target="_blank"rel="nofollow">plos</a>] [<a href="https://doi.org/10.1371/journal.pone.0069268"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Cognitive prognosis of acquired brain injury patients using machine learning techniques</strong><br>J. Serrà, J.L. Arcos, A. García-Rudolph, A. García-Molina, T. Roig, &#x26; J.M. Tormos<br><em>Int. Conf. on Advanced Cognitive Technologies and Applications (COGNITIVE)</em>, pp. 108-113.<br>May 2013. [<a href="http://www.iiia.csic.es/~arcos/papers/54476.pdf"target="_blank"rel="nofollow">iiia</a>] [<a href="https://digital.csic.es/handle/10261/133206"target="_blank"rel="nofollow">csic</a>]</p></blockquote><blockquote><p><strong>Measuring quantitative trends in western popular music</strong><br>J. Serrà, A. Corral, M. Boguñá, M. Haro, &#x26; J.L. Arcos<br><em>CRM-Imperial College Workshop on Complex Systems</em>. Barcelona, Spain. Apr 2013.<br>[<a href="http://www.iiia.csic.es/es/publications/measuring-quantitative-trends-western-popular-music"target="_blank"rel="nofollow">iiia</a>] [<a href="http://www.crm.cat/en/Activities/Pages/ActivityFoldersAndPages/Curs%202012-2013/International-School-and-Research-Workshop-on-Complex-systems.aspx"target="_blank"rel="nofollow">crm</a>]</p></blockquote><blockquote><p><strong>Tonal representations for music retrieval: from version identification to query-by-humming</strong><br>J. Salamon, J. Serrà, &#x26; E. Gómez<br><em>Int. Journal of Multimedia Information Retrieval</em> 2(1): 45-58. Feb 2013.<br>[<a href="http://www.iiia.csic.es/en/publications/tonal-representations-music-retrieval-version-identification-query-humming"target="_blank"rel="nofollow">iiia</a>] [<a href="http://dx.doi.org/10.1007/s13735-012-0026-0"target="_blank"rel="nofollow">doi</a>]</p></blockquote><br>2012<blockquote><p><strong>Structure-based audio fingerprinting for music retrieval</strong><br>P. Grosche, J. Serrà, M. Müller, &#x26; J.L. Arcos<br><em>Int. Soc. for Music Information Retrieval Conf. (ISMIR)</em>, pp. 55-60. Oct 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/structure-based-audio-fingerprinting-music-retrieval"target="_blank"rel="nofollow">iiia</a>] [<a href="http://ismir2012.ismir.net/event/papers/055-ismir-2012.pdf"target="_blank"rel="nofollow">ismir</a>]</p></blockquote><blockquote><p><strong>Folksonomy-based tag recommendation for online audio clip sharing</strong><br>F. Font, J. Serrà, &#x26; X. Serra<br><em>Int. Soc. for Music Information Retrieval Conf. (ISMIR)</em>, pp. 73-78. Oct 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/folksonomy-based-tag-recommendation-online-audio-clip-sharing"target="_blank"rel="nofollow">iiia</a>] [<a href="http://ismir2012.ismir.net/event/papers/073-ismir-2012.pdf"target="_blank"rel="nofollow">ismir</a>]</p></blockquote><blockquote><p><strong>Characterizaztion of intonation in Carnatic music by parametrizing pitch histograms</strong><br>G.K. Koduri, J. Serrà, &#x26; X. Serra<br><em>Int. Soc. for Music Information Retrieval Conf. (ISMIR)</em>, pp. 199-204. Oct 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/characterizaztion-intonation-carnatic-music-parametrizing-pitch-histograms"target="_blank"rel="nofollow">iiia</a>] [<a href="http://ismir2012.ismir.net/event/papers/199-ismir-2012.pdf"target="_blank"rel="nofollow">ismir</a>]</p></blockquote><blockquote><p><strong>Extracting semantic information from an on-line Carnatic music forum</strong><br>M. Sordo, J. Serrà, G.K. Koduri, &#x26; X. Serra<br><em>Int. Soc. for Music Information Retrieval Conf. (ISMIR)</em>, pp. 355-360. Oct 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/extracting-semantic-information-line-carnatic-music-forum"target="_blank"rel="nofollow">iiia</a>] [<a href="http://ismir2012.ismir.net/event/papers/355-ismir-2012.pdf"target="_blank"rel="nofollow">ismir</a>]</p></blockquote><blockquote><p><strong>The importance of detecting boundaries in music structure annotation</strong><br>J. Serrà, M. Müller, P. Grosche, &#x26; J.L. Arcos<br><em>Music Information Retrieval Evaluation eXchange (MIREX)</em>. Oct 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/importance-detecting-boundaries-music-structure-annotation"target="_blank"rel="nofollow">iiia</a>] [<a href="http://www.music-ir.org/mirex/abstracts/2012/SMGA1.pdf"target="_blank"rel="nofollow">mirex</a>]</p></blockquote><blockquote><p><strong>A competitive measure to assess the similarity between two time series</strong><br>J. Serrà &#x26; J.L. Arcos<br><em>Int. Conf. on Case-Based Reasoning (ICCBR)</em>, Lecture Notes in Artificial Intelligence 7466, pp. 414-427. Sep 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/competitive-measure-assess-similarity-between-two-time-series"target="_blank"rel="nofollow">iiia</a>] [<a href="http://dx.doi.org/10.1007/978-3-642-32986-9_31"target="_blank"rel="nofollow">doi</a>] [<a href="http://www.iiia.csic.es/%7Ejserra/downloads/2012_SerraArcos_MJC-Dissim.tar.gz"target="_blank"rel="nofollow">code</a>]</p></blockquote><blockquote><p><strong>The computer as music critic</strong> J. Serrà &#x26; J.L. Arcos<br><em>The New York Times</em>, pp. SR12. September 15, 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/computer-music-critic"target="_blank"rel="nofollow">iiia</a>] [<a href="http://www.nytimes.com/2012/09/16/opinion/sunday/the-computer-as-music-critic.html"target="_blank"rel="nofollow">nytimes</a>]</p></blockquote><blockquote><p><strong>Measuring the evolution of contemporary western popular music</strong><br>J. Serrà, A. Corral, M. Boguñá, M. Haro &#x26; J.L. Arcos<br><em>​Scientific Reports</em> 2: 521. Jul 2012.<br>[<a href="http://www.iiia.csic.es/es/publications/measuring-evolution-contemporary-western-popular-music"target="_blank"rel="nofollow">iiia</a>] [<a href="http://dx.doi.org/10.1038/srep00521"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Characterization and exploitation of community structure in cover song networks</strong><br>J. Serrà, M. Zanin, P. Herrera, &#x26; X. Serra<br><em>Pattern Recognition Letters</em> 33(9): 1032-1041. Jul 2012.<br>[<a href="http://arxiv.org/abs/1108.6003"target="_blank"rel="nofollow">arxiv</a>] [<a href="http://dx.doi.org/10.1016/j.patrec.2012.02.013"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Unsupervised detection of music boundaries by time series structure features</strong><br>J. Serrà, M. Müller, P. Grosche, &#x26; J.L. Arcos<br><em>AAAI Int. Conf. on Artificial Intelligence (AAAI)</em>, pp. 1613-1619. Jul 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/unsupervised-detection-music-boundaries-time-series-structure-features"target="_blank"rel="nofollow">iiia</a>] [<a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/4907"target="_blank"rel="nofollow">aaai</a>]</p></blockquote><blockquote><p><strong>Extracting semantic information from on-line art music discussion forums</strong><br>M. Sordo, J. Serrà, G.K. Koduri, &#x26; X. Serra<br><em>CompMusic Workshop</em>. Jul 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/extracting-semantic-information-line-art-music-discussion-forums"target="_blank"rel="nofollow">iiia</a>] [<a href="http://compmusic.upf.edu/node/130"target="_blank"rel="nofollow">compmusic</a>]</p></blockquote><blockquote><p><strong>Computational analysis of intonation in Indian art music</strong><br>G.K. Koduri, J. Serrà, &#x26; X. Serra<br><em>CompMusic Workshop</em>. Jul 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/computational-analysis-intonation-indian-art-music"target="_blank"rel="nofollow">iiia</a>] [<a href="http://compmusic.upf.edu/node/130"target="_blank"rel="nofollow">compmusic</a>]</p></blockquote><blockquote><p><strong>Automatic identification of samples in hip hop music</strong><br>J. Van Balen, M. Haro, &#x26; J. Serrà<br><em>Int. Symp. on Computer Music Modeling and Retrieval (CMMR)</em>, pp. 544-551. Jun 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/automatic-identification-samples-hip-hop-music"target="_blank"rel="nofollow">iiia</a>] [<a href="http://cmmr2012.eecs.qmul.ac.uk/sites/cmmr2012.eecs.qmul.ac.uk/files/pdf/papers/cmmr2012_submission_19.pdf"target="_blank"rel="nofollow">cmmr</a>]</p></blockquote><blockquote><p><strong>Quantifying the evolution of popular music</strong><br>J. Serrà, A. Corral, M. Boguñá, M. Haro, &#x26; J.L. Arcos<br><em>No Lineal Conf.</em> Jun 2012.<br>[<a href="http://www.iiia.csic.es/es/publications/quantifying-evolution-popular-music"target="_blank"rel="nofollow">iiia</a>] [<a href="http://neptuno.unizar.es/jgg/nolineal2012/programa.html"target="_blank"rel="nofollow">nolineal</a>]</p></blockquote><blockquote><p><strong>Patterns, regularities, and evolution of contemporary popular music</strong><br>J. Serrà, A. Corral, M. Boguñá, M. Haro, &#x26; J.L. Arcos<br><em>Complexitat.Cat Workshop</em>. May 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/patterns-regularities-and-evolution-contemporary-popular-music"target="_blank"rel="nofollow">iiia</a>] [<a href="http://www.complexitat.cat/seminars/112/"target="_blank"rel="nofollow">complexitat.cat</a>]</p></blockquote><blockquote><p><strong>Power-law distribution in encoded MFCC frames of speech, music, and environmental sound signals</strong><br>M. Haro, J. Serrà, A. Corral, &#x26; P. Herrera<br><em>Workshop on Advances in Music Information Research (AdMIRe), Int. World Wide Web Conf. (WWW)</em>, pp. 895-902. Apr 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/power-law-distribution-encoded-mfcc-frames-speech-music-and-environmental-sound-signals"target="_blank"rel="nofollow">iiia</a>] [<a href="http://www2012.wwwconference.org/proceedings/companion/p895.pdf"target="_blank"rel="nofollow">www</a>]</p></blockquote><blockquote><p><strong>Melody, bassline, and harmony representations for music version identification</strong><br>J. Salamon, J. Serrà, &#x26; E. Gómez<br><em>Workshop on Advances in Music Information Research (AdMIRe), Int. World Wide Web Conf. (WWW)</em>, pp. 887-894. Apr 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/melody-bassline-and-harmony-representations-music-version-identification"target="_blank"rel="nofollow">iiia</a>] [<a href="http://www2012.wwwconference.org/proceedings/companion/p887.pdf"target="_blank"rel="nofollow">www</a>]</p></blockquote><blockquote><p><strong>Audio content-based music retrieval</strong><br>P. Grosche, M. Müller, &#x26; J. Serrà<br><em>Multimodal Music Processing</em>, M. Müller, M. Goto, and M. Schedl eds., Dagstuhl Follow-Ups, Dagstuhl Publishing, Wadern, Germany, vol. 3, ch. 9, pp. 157-174. Apr 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/audio-content-based-music-retrieval"target="_blank"rel="nofollow">iiia</a>] [<a href="http://drops.dagstuhl.de/opus/portals/dfu/index.php?semnr=12002"target="_blank"rel="nofollow">dagstuhl</a>]</p></blockquote><blockquote><p><strong>Zipf's law in short-time timbral codings of speech, music, and environmental sound signals</strong><br>M. Haro, J. Serrà, P. Herrera, &#x26; A. Corral.<br><em>PLoS ONE</em> 7(3): e33993. Mar 2012.<br>[<a href="http://www.iiia.csic.es/en/publications/zipf-s-law-short-time-timbral-codings-speech-music-and-environmental-sound-signals-0"target="_blank"rel="nofollow">iiia</a>] [<a href="http://dx.doi.org/10.1371/journal.pone.0033993"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Predictability of music descriptor time series and its application to cover song detection</strong><br>J. Serrà, H. Kantz, X. Serra, &#x26; R.G. Andrzejak<br><em>IEEE Trans. on Audio, Speech and Language Processing</em> 20(2): 514-525. Feb 2012.<br>[<a href="http://mtg.upf.edu/node/1738"target="_blank"rel="nofollow">mtg</a>] [<a href="http://dx.doi.org/10.1109/TASL.2011.2162321"target="_blank"rel="nofollow">doi</a>]</p></blockquote><br>2011<blockquote><p><strong>Identification of versions of the same musical composition: audio content-based approaches and post-processing steps</strong><br>J. Serrà<br>LAP Lambert Academic Publishing, Saarbrücken, Germany. ISBN 978-3-8473-2785-1. Dec 2011.<br>[<a href="http://www.amazon.com/Identification-Versions-Same-Musical-Composition/dp/3847327852"target="_blank"rel="nofollow">amazon</a>] [<a href="http://www.barnesandnoble.com/w/identification-of-versions-of-the-same-musical-composition-joan-serr/1108137951"target="_blank"rel="nofollow">bn</a>]</p></blockquote><blockquote><p><strong>Assessing the tuning of sung Indian classical music</strong><br>J. Serrà, G.K. Koduri, M. Miron, &#x26; X. Serra<br><em>Int. Soc. for Music Information Retrieval Conf. (ISMIR)</em>, pp. 263-268. Oct 2011.<br>[<a href="http://mtg.upf.edu/node/2274"target="_blank"rel="nofollow">mtg</a>] [<a href="http://ismir2011.ismir.net/papers/OS2-2.pdf"target="_blank"rel="nofollow">ismir</a>]</p></blockquote><blockquote><p><strong>Computational approaches for the understanding of melody and rhythm in Carnatic music</strong><br>G.K. Koduri, M. Miron, J. Serrà, &#x26; X. Serra<br><em>Int. Soc. for Music Information Retrieval Conf. (ISMIR)</em>, pp. 157-162. Oct 2011.<br>[<a href="http://mtg.upf.edu/node/2281"target="_blank"rel="nofollow">mtg</a>] [<a href="http://ismir2011.ismir.net/papers/PS2-16.pdf"target="_blank"rel="nofollow">ismir</a>]</p></blockquote><blockquote><p><strong>Unifying low-level and high-level music similarity measures</strong><br>D. Bogdanov, J. Serrà, N. Wack, P. Herrera, &#x26; X. Serra<br><em>IEEE Trans. on Multimedia</em> 13(4): 687-701. Aug 2011.<br>[<a href="http://mtg.upf.edu/node/1689"target="_blank"rel="nofollow">mtg</a>] [<a href="http://dx.doi.org/10.1109/TMM.2011.2125784"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Method for calculating measures of similarity between time signals</strong><br>J. Serrà<br><em>Patent</em> US 2011/0178615, published July 21, 2011. Priority num. ES20090001057-20090423. Also published as ES 2354330 (Método para calcular medidas de similitud entre señales temporales).<br>[<a href="http://www.freepatentsonline.com/y2011/0178615.html"target="_blank"rel="nofollow">fpo</a>] [<a href="http://worldwide.espacenet.com/publicationDetails/biblio?FT=D&#x26;date=20110721&#x26;DB=EPODOC&#x26;locale=en_EP&#x26;CC=US&#x26;NR=2011178615A1&#x26;KC=A1"target="_blank"rel="nofollow">espacenet</a>]</p></blockquote><blockquote><p><strong>Nonlinear audio recurrence analysis with application to genre classification</strong><br>J. Serrà, C.A. De Los Santos, &#x26; R.G. Andrzejak<br><em>IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP)</em>, pp. 169-172. May 2011.<br>[<a href="http://mtg.upf.edu/node/1861"target="_blank"rel="nofollow">mtg</a>] [<a href="http://dx.doi.org/10.1109/ICASSP.2011.5946367"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Identification of versions of the same musical composition by processing audio descriptions</strong> J. Serrà<br><em>PhD Thesis</em>. Universitat Pompeu Fabra, Barcelona, Spain. Mar 2011.<br>[<a href="http://mtg.upf.edu/node/1951"target="_blank"rel="nofollow">mtg</a>] [<a href="http://tdx.cat/handle/10803/22674"target="_blank"rel="nofollow">tdx</a>]</p></blockquote><blockquote><p><strong>Cover song networks: analysis and accuracy increase</strong><br>J. Serrà, M. Zanin, &#x26; P. Herrera<br><em>Int. Journal of Complex Systems in Science</em> 1: 55-59. Jan 2011.<br>[<a href="http://mtg.upf.edu/node/1686"target="_blank"rel="nofollow">mtg</a>]</p></blockquote><h2 id="prehistoric-2007-2010">Prehistoric (2007-2010)<a aria-hidden class="header-link"tabindex="-1"href="#prehistoric-2007-2010">#</a></h2><br>2010<blockquote><p><strong>Model-based cover song detection via threshold autoregressive forecasts</strong><br>J. Serrà, H. Kantz, &#x26; R.G. Andrzejak<br><em>Workshop on Music and Machine Learning (MML), ACM Int. Conf. on Multimedia (ACM-MM)</em>, pp. 13-16. Oct 2010.<br>[<a href="http://mtg.upf.edu/node/1704"target="_blank"rel="nofollow">mtg</a>] [<a href="http://dx.doi.org/10.1145/1878003.1878008"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Unsupervised accuracy improvement for cover song detection using spectral connectivity network</strong><br>M. Lagrange &#x26; J. Serrà<br><em>Int. Soc. for Music Information Retrieval Conf. (ISMIR)</em>, pp. 595-600. Aug 2010.<br>[<a href="http://mtg.upf.edu/node/1682"target="_blank"rel="nofollow">mtg</a>] [<a href="http://ismir2010.ismir.net/proceedings/ismir2010-102.pdf"target="_blank"rel="nofollow">ismir</a>]</p></blockquote><blockquote><p><strong>Hybrid music similarity measure</strong><br>D. Bogdanov, J. Serrà, N. Wack, &#x26; P. Herrera<br><em>Music Information Retrieval Evaluation eXchange (MIREX)</em>. Aug 2010.<br>[<a href="http://mtg.upf.edu/node/1828"target="_blank"rel="nofollow">mtg</a>] [<a href="http://www.music-ir.org/mirex/abstracts/2010/BWL1.pdf"target="_blank"rel="nofollow">mirex</a>]</p></blockquote><blockquote><p><strong>Music classification using high-level models</strong><br>N. Wack, C. Laurier, O. Meyers, R. Marxer, D. Bogdanov, J. Serrà, E. Gómez, &#x26; P. Herrera<br><em>Music Information Retrieval Evaluation eXchange (MIREX)</em>. Aug 2010.<br>[<a href="http://mtg.upf.edu/node/1778"target="_blank"rel="nofollow">mtg</a>] [<a href="http://www.music-ir.org/mirex/abstracts/2010/WLB1.pdf"target="_blank"rel="nofollow">mirex</a>]</p></blockquote><blockquote><p><strong>Cover song networks: analysis and accuracy increase</strong><br>J. Serrà, M. Zanin, &#x26; P. Herrera<br><em>Net-Works Int. Conf.</em> Jun 2010.<br>[<a href="http://mtg.upf.edu/node/1678"target="_blank"rel="nofollow">mtg</a>] [<a href="http://bifi.es/events/networks2010/book_abstracts.pdf"target="_blank"rel="nofollow">net-works</a>]</p></blockquote><blockquote><p><strong>Indexing music by mood: design and integration of an automatic content-based annotator</strong><br>C. Laurier, O. Meyers, J. Serrà, M. Blech, P. Herrera, &#x26; X. Serra<br><em>Multimedia Tools and Applications</em> 48(1): 161-184. May 2010.<br>[<a href="http://mtg.upf.edu/node/1400"target="_blank"rel="nofollow">mtg</a>] [<a href="http://dx.doi.org/10.1007/s11042-009-0360-2"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Audio cover song identification and similarity: background, approaches, evaluation, and beyond</strong><br>J. Serrà, E. Gómez, &#x26; P. Herrera<br><em>Advances in Music Information Retrieval</em>, Z. W. Ras and A. A. Wieczorkowska eds., Studies in Computational Intelligence series, Springer, Berlin, Germany, vol. 274, ch. 14, pp. 307-332. Mar 2010.<br>[<a href="http://mtg.upf.edu/node/1389"target="_blank"rel="nofollow">mtg</a>] [<a href="http://dx.doi.org/10.1007/978-3-642-11674-2_14"target="_blank"rel="nofollow">doi</a>]</p></blockquote><br>2009<blockquote><p><strong>From low-level to high-level: comparative study of music similarity measures</strong><br>D. Bogdanov, J. Serrà, N. Wack, &#x26; P. Herrera<br><em>Workshop on Advances in Music Information Research (AdMIRe), IEEE Int. Symp. on Multimedia</em>, pp. 453-458. Dec 2009.<br>[<a href="http://mtg.upf.edu/node/1406"target="_blank"rel="nofollow">mtg</a>] [<a href="http://dx.doi.org/10.1109/ISM.2009.72"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Unsupervised detection of cover song sets: accuracy improvement and original identification</strong><br>J. Serrà, M. Zanin, C. Laurier, &#x26; M. Sordo<br><em>Int. Soc. for Music Information Retrieval Conf. (ISMIR)</em>, pp. 225-230. Oct 2009.<br>[<a href="http://mtg.upf.edu/node/1407"target="_blank"rel="nofollow">mtg</a>] [<a href="http://ismir2009.ismir.net/proceedings/PS2-6.pdf"target="_blank"rel="nofollow">ismir</a>]</p></blockquote><blockquote><p><strong>Music mood representations from social tags</strong><br>C. Laurier, M. Sordo, J. Serrà, &#x26; P. Herrera<br><em>Int. Soc. for Music Information Retrieval Conf. (ISMIR)</em>, pp. 381-386. Oct 2009.<br>[<a href="http://mtg.upf.edu/node/1466"target="_blank"rel="nofollow">mtg</a>] [<a href="http://ismir2009.ismir.net/proceedings/OS5-4.pdf"target="_blank"rel="nofollow">ismir</a>]</p></blockquote><blockquote><p><strong>The discipline formerly known as MIR</strong><br>P. Herrera, J. Serrà, C. Laurier, E. Guaus, E. Gómez, &#x26; X. Serra<br><em>Int. Society for Music Information Retrieval Conf. (ISMIR), special session on the Future of MIR (fMIR)</em>. Oct 2009.<br>[<a href="http://mtg.upf.edu/node/1509"target="_blank"rel="nofollow">mtg</a>] [<a href="http://www.columbia.edu/%7Etb2332/fmir/Papers/Herrera-fmir.pdf"target="_blank"rel="nofollow">fmir</a>]</p></blockquote><blockquote><p><strong>Cover song retrieval by cross recurrence quantification and unsupervised set detection</strong><br>J. Serrà, M. Zanin, &#x26; R.G. Andrzejak<br><em>Music Information Retrieval Evaluation eXchange (MIREX)</em>. Oct 2009.<br>[<a href="http://mtg.upf.edu/node/1517"target="_blank"rel="nofollow">mtg</a>] [<a href="http://www.music-ir.org/mirex/abstracts/2009/SZA.pdf"target="_blank"rel="nofollow">mirex</a>]</p></blockquote><blockquote><p><strong>Music type groupers (MTG): generic music classification algorithms</strong><br>N. Wack, E. Guaus, C. Laurier, O. Meyers, R. Marxer, D. Bogdanov, J. Serrà, &#x26; P. Herrera<br><em>Music Information Retrieval Evaluation eXchange (MIREX)</em>. Oct 2009.<br>[<a href="http://mtg.upf.edu/node/1518"target="_blank"rel="nofollow">mtg</a>] [<a href="http://www.music-ir.org/mirex/abstracts/2009/MTG_train.pdf"target="_blank"rel="nofollow">mirex</a>]</p></blockquote><blockquote><p><strong>Hybrid similarity measures for music recommendation</strong><br>D. Bogdanov, J. Serrà, N. Wack, &#x26; P. Herrera<br><em>Music Information Retrieval Evaluation eXchange (MIREX)</em>. Oct 2009.<br>[<a href="http://mtg.upf.edu/node/1515"target="_blank"rel="nofollow">mtg</a>] [<a href="http://www.music-ir.org/mirex/abstracts/2009/MIREX2009-sim-BSWH1-BSWH2.pdf"target="_blank"rel="nofollow">mirex</a>]</p></blockquote><blockquote><p><strong>Assessing the results of a cover song identification system with coverSSSSearch</strong><br>J. Serrà<br>Demo Session at the <em>Int. Soc. for Music Information Retrieval Conf. (ISMIR)</em>. Oct 2009.<br>[<a href="http://mtg.upf.edu/node/1553"target="_blank"rel="nofollow">mtg</a>]</p></blockquote><blockquote><p><strong>Cross recurrence quantification for cover song identification</strong><br>J. Serrà, X. Serra, &#x26; R.G. Andrzejak<br><em>New Journal of Physics</em> 11: 093017. Sep 2009.<br>[<a href="http://mtg.upf.edu/node/1390"target="_blank"rel="nofollow">mtg</a>] [<a href="http://dx.doi.org/10.1088/1367-2630/11/9/093017"target="_blank"rel="nofollow">doi</a>] [<a href="http://www.iiia.csic.es/%7Ejserra/downloads/2009_SerraZA_MIREX-Covers.tar.gz"target="_blank"rel="nofollow">code</a>]</p></blockquote><blockquote><p><strong>Shape-based spectral contrast descriptor</strong><br>V. Akkermans, J. Serrà, &#x26; P. Herrera<br><em>Sound and Music Computing Conf. (SMC)</em>, pp. 143-148. Jul 2009.<br>[<a href="http://mtg.upf.edu/node/1327"target="_blank"rel="nofollow">mtg</a>] [<a href="http://smc2009.smcnetwork.org/programme/pdfs/174.pdf"target="_blank"rel="nofollow">smc</a>]</p></blockquote><blockquote><p><strong>Music mood annotator design and integration</strong><br>C. Laurier, O. Meyers, J. Serrà, M. Blech, &#x26; P. Herrera<br><em>Int. Workshop on Content-Based Multimedia Indexing (CBMI)</em>, pp. 156-161. Jun 2009.<br>[<a href="http://mtg.upf.edu/node/1260"target="_blank"rel="nofollow">mtg</a>] [<a href="http://dx.doi.org/10.1109/CBMI.2009.45"target="_blank"rel="nofollow">doi</a>]</p></blockquote><br>2008<blockquote><p><strong>Music similarity systems and methods using descriptors</strong><br>E. Gómez, P. Herrera, P. Cano, J. Janer, J. Serrà, J. Bonada, S. El-Hajj, T. Aussenac, &#x26; G. Holmberg<br><em>Patent</em> US 2008/300702, published December 31, 2008. Priority nums. US20070946860P-20070628, US20070970109P-20070905, and US20070988714P-20071116. Also published as WO 2009/001202.<br>[<a href="http://www.freepatentsonline.com/y2008/0300702.html"target="_blank"rel="nofollow">fpo</a>] [<a href="http://worldwide.espacenet.com/publicationDetails/biblio?FT=D&#x26;date=20081231&#x26;DB=EPODOC&#x26;locale=en_EP&#x26;CC=WO&#x26;NR=2009001202A1&#x26;KC=A1"target="_blank"rel="nofollow">espacenet</a>]</p></blockquote><blockquote><p><strong>Statistical analysis of chroma features in western music predicts human judgments of tonality</strong><br>J. Serrà, E. Gómez, P. Herrera, &#x26; X. Serra<br><em>Journal of New Music Research</em> 37(4): 299-309. Dec 2008.<br>[<a href="http://mtg.upf.edu/node/1250"target="_blank"rel="nofollow">mtg</a>] [<a href="http://dx.doi.org/10.1080/09298210902894085"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Transposing chroma representations to a common key</strong><br>J. Serrà, E. Gómez, &#x26; P. Herrera<br><em>Int. Conf. on The Use of Symbols to Represent Music and Multimedia Objects</em>, pp. 45-48. Oct 2008.<br>[<a href="http://mtg.upf.edu/node/909"target="_blank"rel="nofollow">mtg</a>] [<a href="http://www.ieeecs-tccgm.dico.unimi.it/download/proceedings_2008.pdf"target="_blank"rel="nofollow">unimi</a>]</p></blockquote><blockquote><p><strong>Improving binary similarity and local alignment for cover song detection</strong><br>J. Serrà, E. Gómez, &#x26; P. Herrera<br><em>Music Information Retrieval Evaluation eXchange (MIREX)</em>. Sep 2008.<br>[<a href="http://mtg.upf.edu/node/1028"target="_blank"rel="nofollow">mtg</a>] [<a href="http://www.music-ir.org/mirex/abstracts/2008/CS_Serra.pdf"target="_blank"rel="nofollow">mirex</a>]</p></blockquote><blockquote><p><strong>Chroma binary similarity and local alignment applied to cover song identification</strong><br>J. Serrà, E. Gómez, P. Herrera, &#x26; X. Serra<br><em>IEEE Trans. on Audio, Speech and Language Processing</em> 16(6): 1138-1152. Aug 2008.<br>[<a href="http://mtg.upf.edu/node/919"target="_blank"rel="nofollow">mtg</a>] [<a href="http://dx.doi.org/10.1109/TASL.2008.924595"target="_blank"rel="nofollow">doi</a>]</p></blockquote><blockquote><p><strong>Audio cover song identification based on tonal sequence alignment</strong><br>J. Serrà &#x26; E. Gómez<br><em>IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 61-64. Apr 2008.<br>[<a href="http://mtg.upf.edu/node/78"target="_blank"rel="nofollow">mtg</a>] [<a href="http://dx.doi.org/10.1109/ICASSP.2008.4517546"target="_blank"rel="nofollow">doi</a>]</p></blockquote><br>2007<blockquote><p><strong>A qualitative assessment of measures for the evaluation of a cover song identification system</strong><br>J. Serrà<br><em>Int. Conf. on Music Information Retrieval (ISMIR)</em>, pp. 319-322. Sep 2007.<br>[<a href="http://mtg.upf.edu/node/521"target="_blank"rel="nofollow">mtg</a>] [<a href="http://ismir2007.ismir.net/posters/ISMIR2007_p319_serra_poster.pdf"target="_blank"rel="nofollow">ismir</a>]</p></blockquote><blockquote><p><strong>A cover song identification system based on sequences of tonal descriptors</strong><br>J. Serrà &#x26; E. Gómez<br><em>Music Information Retrieval Evaluation eXchange (MIREX)</em>. Sep 2007.<br>[<a href="http://mtg.upf.edu/node/537"target="_blank"rel="nofollow">mtg</a>] [<a href="http://www.music-ir.org/mirex/abstracts/2007/CS_serra.pdf"target="_blank"rel="nofollow">mirex</a>]</p></blockquote><blockquote><p><strong>Music similarity based on sequences of descriptors: tonal features applied to cover song identification</strong><br>J. Serrà<br><em>MSc Thesis</em>. Universitat Pompeu Fabra, Barcelona, Spain. Sep 2007.<br>[<a href="http://mtg.upf.edu/node/2207"target="_blank"rel="nofollow">mtg</a>]</p></blockquote></span><h1 id="talks">Talks<a aria-hidden class="header-link"tabindex="-1"href="#talks">#</a></h1><span style="color: DarkGrey;"><ul><li><p><strong>Imagination in power! Deep generative models with a focus on speech and music</strong>: <a href="https://casadecultura.org/cicles/675/ultimes-fronteres-la-ciencia-del-segle-xxi"target="_blank"rel="nofollow">Casa de Cultura de Girona</a> (12/5/2022).</p></li><li><p><strong>Universal, generative speech enhancement</strong>: Keynote at the <a href="https://sites.google.com/view/deep-learning-barcelona-2021/"target="_blank"rel="nofollow">Deep Learning Barcelona Symp. 2021</a> (23/12/2021) [<a href="https://youtu.be/pSGES0_XqaE"target="_blank"rel="nofollow">youtube</a>, min 3].</p></li><li><p><strong>Deep generative audio at Dolby</strong>: <a href="https://www.udg.edu/"target="_blank"rel="nofollow">Universitat de Girona</a> - <a href="https://www.udg.edu/ca/eps/escola-politecnica-superior/detall-activitats/eventid/18046"target="_blank"rel="nofollow">Cicle de conferències Patronat/EPS</a> (30/11/2021).</p></li><li><p><strong>Understanding and visualizing speech quality</strong>: Keynote at the <a href="https://webaudioconf2021.com/"target="_blank"rel="nofollow">Web Audio Conf. 2021</a> (13/7/2021) [<a href="https://youtu.be/E4q5a82Ou1I"target="_blank"rel="nofollow">youtube</a>]. With J. DeLancey.</p></li><li><p><strong>Version identification in the 20s</strong>: Tutorial at the Int. Soc. for Music Information Retrieval Conf. (11/10/2020) [<a href="https://program.ismir2020.net/tutorials.html"target="_blank"rel="nofollow">ismir</a>] [<a href="https://docs.google.com/presentation/d/17GDjTE9GV0cWxpYlsiXLvgPkVAg70Ho4RwPUyyL-j0U/edit#slide=id.g92d76a74bf_2_28"target="_blank"rel="nofollow">slides</a>]. With F. Yesiler &#x26; C. Tralie.</p></li><li><p><strong>From correlation to imagination - GANs and deep generative models</strong>: Telefónica Talks - Madrid (27/9/2018), Telefónica Barcelona Talk (11/10/2018), <a href="https://www.salleurl.edu/en"target="_blank"rel="nofollow">Enginyeria La Salle</a> - <a href="https://www.url.edu/en"target="_blank"rel="nofollow">Universitat Ramon Llull</a> (26/3/2019), <a href="https://www.uvic.cat/"target="_blank"rel="nofollow">Universitat de Vic</a> - <a href="https://mon.uvic.cat/udivulga/event/11ena-edicio-jornada-de-mecatronica/"target="_blank"rel="nofollow">Jornades de Mecatrònica</a> (9/5/2019), <a href="http://www.udl.es/ca/"target="_blank"rel="nofollow">Universitat de Lleida</a> - Màster Gestió Administrativa (27/5/2019), Conf. of the <a href="https://www.acia.cat/"target="_blank"rel="nofollow">Catalan Association for Artificial Intelligence</a> - <a href="https://agenda.uib.es/29216/speakers/22nd-international-conference-of-the-catalan-association-for-artificial-intelligence.html"target="_blank"rel="nofollow">CCIA 2019</a> (24/10/2019).</p></li><li><p><strong>Deep learning at Telefónica Research</strong>: <a href="https://www.dolby.com/us/en/about/contact-us/dolby-offices-worldwide.html"target="_blank"rel="nofollow">Dolby Labs - Barcelona</a> (14/3/2018), <a href="https://barcelonatechnologyschool.com/"target="_blank"rel="nofollow">Barcelona Technology School</a> (26/6/2018).</p></li><li><p><strong>Overcoming catastrophic forgetting with hard attention to the task</strong>: <a href="http://www.cvc.uab.es/"target="_blank"rel="nofollow">CVC-UAB</a> - <a href="http://www.cvc.uab.es/?p=3622"target="_blank"rel="nofollow">Lifelong Learning Seminar</a> (16/2/2018), <a href="https://bcn.ai/"target="_blank"rel="nofollow">bcn.ai</a> (6/9/2018).</p></li><li><p><strong>Unintuitive properties of deep neural networks</strong>: <a href="https://etsetb.upc.edu/en"target="_blank"rel="nofollow">UPC/TelecomBCN</a> - <a href="https://telecombcn-dl.github.io/2018-idl/"target="_blank"rel="nofollow">IDL Winter School</a> (30/1/2018), <a href="https://ec.europa.eu/jrc/en"target="_blank"rel="nofollow">EU Science Hub</a> - <a href="https://ec.europa.eu/jrc/en/event/workshop/kickoff-workshop-human-behaviour-and-machine-intelligence-humaint"target="_blank"rel="nofollow">Human Behavior and Machine Intelligence Workshop</a> (5/3/2018).</p></li><li><p><strong>Facts and myths about deep learning</strong>: <a href="http://databeersbcn.com/"target="_blank"rel="nofollow">DataBeersBCN</a> (4/10/2016) [<a href="https://www.youtube.com/watch?v=kte3xBwj7k8"target="_blank"rel="nofollow">youtube</a>], <a href="http://mtg.upf.edu/node/3594"target="_blank"rel="nofollow">UPF MTG-Compmusic Seminar</a> (18/11/2016) [<a href="https://youtu.be/nFnPoafwyyI?list=PLf9oYraEW2rcrSf2AtMARDIsdXGwpIReU"target="_blank"rel="nofollow">youtube</a>], <a href="https://telecombcn-dl.github.io/2017-dlsl/"target="_blank"rel="nofollow">UPC-TelecomBCN DLSL Winter School</a> (27/1/2017) [<a href="https://www.youtube.com/watch?v=xbI8WxA5-mg"target="_blank"rel="nofollow">youtube</a>], <a href="http://www.bdebate.org/en/forum/artificial-intelligence-next-step-evolution"target="_blank"rel="nofollow">B-Debate on Artificial Intelligence</a> (7-8/3/2017) [<a href="https://vimeo.com/album/4516480/video/211630902"target="_blank"rel="nofollow">vimeo</a>], <a href="http://www.iiia.csic.es/en/activities"target="_blank"rel="nofollow">IIIA-CSIC Seminars</a> (15/3/2017), <a href="http://www.madridml.com/en/"target="_blank"rel="nofollow">Madrid Machine Learning</a> (11/5/2017).</p></li><li><p><strong>Note onset deviations as musical piece signatures</strong>: <a href="http://www.upf.edu/pra/3382/20506.html"target="_blank"rel="nofollow">UPF - Música i Publicitat</a> (12/11/2014).</p></li><li><p><strong>Patterns, regularities, and evolution of contemporary western popular music</strong>: <a href="http://www.crm.cat/AppliedMathematicsGroup/CAMP_seminar.htm"target="_blank"rel="nofollow">CRM - CAMP seminar</a> (3/5/2012), <a href="http://www.upf.edu/pra/3382/20506.html"target="_blank"rel="nofollow">UPF - Música i Publicitat</a> (6/11/2012, 13/11/2013).</p></li><li><p><strong>Machine learning for music discovery</strong>: Tutorial at the Int. Symp. on Frontiers of Research on Speech and Music (20/01/2012) [<a href="http://compmusic.upf.edu/node/111"target="_blank"rel="nofollow">compmusic</a>] [<a href="http://www.iiia.csic.es/%7Ejserra/downloads/2012_FRSM_tutorial_jserra.pdf"target="_blank"rel="nofollow">slides</a>].</p></li><li><p><strong>Audio content-based music retrieval</strong>: Tutorial at the Int. Soc. for Music Information Retrieval Conf. (24/10/2011) [<a href="http://mtg.upf.edu/node/2275"target="_blank"rel="nofollow">mtg</a>] [<a href="http://ismir2011.ismir.net/tutorials.html"target="_blank"rel="nofollow">ismir</a>] [<a href="http://www.iiia.csic.es/~jserra/downloads/2011_MuellerSerra_MusicRetrieval_Tutorial-ISMIR_handouts-6.pdf"target="_blank"rel="nofollow">slides</a>]. With M. Müller.</p></li><li><p><strong>Model-based cover song detection via threshold autoregressive forecasts</strong>: <a href="http://www.talp.cat/talp/index.php/en"target="_blank"rel="nofollow">UPC - TALP</a> (6/10/2010).</p></li><li><p><strong>Music descriptor time series</strong>: <a href="http://www.mpipks-dresden.mpg.de/"target="_blank"rel="nofollow">Max Planck Institute for the Physics of Complex Systems</a> (5/2/2010).</p></li><li><p><strong>Audio cover song identification</strong>: UPF - Dept. of Information and Communication Technologies (25/10/2007).</p></li><li><p>​<strong>Tecnologia per al descobriment de cançons i per la predicció d'èxits musicals</strong>: <a href="http://www.dtic.upf.edu/%7Eperfe/cursos/seminarisonologia/"target="_blank"rel="nofollow">ESMUC - Seminaris de Sonologia</a> (9/10/2006).</p></li></ul></span><h1 id="misc">Misc<a aria-hidden class="header-link"tabindex="-1"href="#misc">#</a></h1><h2 id="experienceeducation">Experience/education<a aria-hidden class="header-link"tabindex="-1"href="#experienceeducation">#</a></h2><span style="color: DarkGrey;"><ul><li><p><strong><a href="https://www.dolby.com/"target="_blank"rel="nofollow">Dolby Laboratories</a></strong> (2019-Present). Research scientist. <a href="https://dolby.io/audio-research/"target="_blank"rel="nofollow">AI team</a>, Advanced Technology Group. ​</p></li><li><p><strong><a href="http://www.tid.es/"target="_blank"rel="nofollow">Telefónica R&#x26;D</a></strong> (2015-2019). Research scientist. Machine Learning, Data Mining and User Modeling Group.</p></li><li><p><strong><a href="http://www.csic.es/"target="_blank"rel="nofollow">Spanish National Research Council</a></strong> (2011-2015). Postdoctoral researcher. Artificial Intelligence Research Institute (IIIA-CSIC). Dept. of Learning Systems.</p></li><li><p><strong><a href="http://www.mpi-inf.mpg.de/"target="_blank"rel="nofollow">Max Planck Institute for Computer Science</a></strong> (Nov 2011-Jan 2012). Invited postdoctoral researcher. Research group on Multimedia Information Retrieval and Music Processing.</p></li><li><p><strong><a href="http://www.upf.edu/"target="_blank"rel="nofollow">Universitat Pompeu Fabra</a></strong> (2006-2011). MSc candidate, PhD candidate, postdoctoral researcher, and teaching assistant. Dept. of Information and Communication Technologies. Music Technology Group.</p></li><li><p><strong><a href="http://www.mpipks-dresden.mpg.de/"target="_blank"rel="nofollow">Max Planck Institute for the Physics of Complex Systems</a></strong> (Feb-Jun 2010). Guest scientist. Research group on Nonlinear Dynamics and Time Series Analysis.</p></li><li><p><strong><a href="http://www.polyphonichmi.com/"target="_blank"rel="nofollow">Polyphonic HMI</a></strong> (2005-2006). Research engineer. R&#x26;D Dept.</p></li><li><p><strong><a href="http://www.salleurl.edu/"target="_blank"rel="nofollow">Enginyeria La Salle, Universitat Ramon Llull</a></strong> (1998-2004). Undergraduate studies. Electronics Engineering and Telecommunications Engineering (two degrees).</p></li></ul></span><h2 id="scientific-service">Scientific service<a aria-hidden class="header-link"tabindex="-1"href="#scientific-service">#</a></h2><span style="color: DarkGrey;"><ul><li><p><strong>Journal referee</strong>: Connection Science (2007), EURASIP Journal on Advances on Signal Processing (2010), IEEE Journal of Selected Topics in Signal Processing (2011), Journal of New Music Research (2012-2014), Journal of Intelligent Information Systems (2012), Artificial Intelligence (2013-2014), IEEE Trans. on Audio, Speech and Language Processing (2013-2014), IEEE Trans. on Multimedia (2014-2015), Knowledge and Information Systems (2014), PLoS ONE (2014), Information Sciences (2014), EURASIP Journal on Audio, Speech, and Music Processing (2015), ACM Trans. on Multimedia Computing, Communications, and Applications (2015-2016), Mathematical Problems in Engineering (2016), Knowledge-Based Systems (2017).<br><em>--- Since 2017, I am not reviewing for journals that have publication or article access paywalls.</em></p></li><li><p><strong>Conference reviewer or area chair</strong>: ISMIR (2008, 2009, 2010, 2011, 2012, 2013, 2014), ICMC (2009, 2010), SMC (2010, 2011, 2012, 2013), ICASSP (2011, 2012, 2013, 2016), ACM-MM (2013, 2014), AES (2013), TRI (2015), UbiComp (2015), AAAI (2016, 2017, 2018), ICWSM (2017), NIPS-ML4Audio (2017), CCIA (2018), KDD (2019), IJCAI (2019), NeurIPS (2020, 2021), ICLR (2021, 2022), ICML (2021, 2022), INTERSPEECH (2021, 2022).<br><em>--- Since 2018, I am not reviewing for conferences that have publication or article access paywalls.</em></p></li><li><p><strong>Conference organization</strong>: MIRUM (2011, 2012), SMC 2010, IberSpeech 2018, DLBCN (2018, 2019, 2021).</p></li><li><p><strong>Research funding agencies</strong>: CONICYT (2017).</p></li><li><p><strong>Member of the ELLIS Society</strong> (2022).</p></li><li><p><strong>​Others</strong>: Panelist at AAAI Doctoral Consortium (2012), reviewer for MIT Technology Review - Innovators under 35 (2018), advisor at bcn.ai (2018-2020).</p></li></ul></span><h2 id="projects">Projects<a aria-hidden class="header-link"tabindex="-1"href="#projects">#</a></h2><p><em>[I'm currently not involved in funded R&#x26;D projects, but in the past I was...]</em></p><p>Publicly-funded</p><span style="color: DarkGrey;"><ul><li><p>Accordion (2019-2021): <strong>Adaptive edge/cloud compute and network continuum over a heterogeneous sparse edge infrastructure to support nextgen applications</strong>. European Commission: RIA-2019-871793 (as PI, submitted proposal).</p></li><li><p><a href="https://www.ibidaas.eu/"target="_blank"rel="nofollow">i-BiDaaS</a> (2018-2020): <strong>Industrial-driven big data as a self-service solution</strong>. European Commission: RIA-2017-780787.</p></li><li><p><a href="http://bison-project.eu/"target="_blank"rel="nofollow">BISON</a> (2015-2017): <strong>Big speech data analytics for contact centers</strong>. European Commission: ICT-2014-15-645323.</p></li><li><p><a href="http://www.iiia.csic.es/en/project/cognitio"target="_blank"rel="nofollow">COGNITIO</a> (2013-2015): <strong>Multiparametric analysis of image, clinical data and therapy for the optimization of cognitive rehabilitation on TBI</strong>. Spanish Government, Ministry of Economy and Competitiveness: TIN-2012-38450-C03-03.</p></li><li><p><a href="http://www.iiia.csic.es/praise/"target="_blank"rel="nofollow">PRAISE</a> (2012-2015): <strong>Practice and performance analysis inspiring social education</strong>. European Commission: ICT-2011-8-318770.</p></li><li><p><a href="http://worthplay.upf.edu/"target="_blank"rel="nofollow">WorthPlay</a> (2012-2014): <strong>Worth playing: digital games for active and positive ageing</strong>. CSIC General Foundation and Obra Social La Caixa: "Proyecto cero" on ageing 2011.</p></li><li><p><a href="http://compmusic.upf.edu/"target="_blank"rel="nofollow">CompMusic</a> (2011-2016): <strong>Computational models for the discovery of the world's music</strong>. European Research Council: ERC grant agreement 267583.</p></li><li><p><a href="http://www.cenitbuscamedia.es/"target="_blank"rel="nofollow">BuscaMedia</a> (2010-2011): <strong>Automatic generation of audiovisual narrative</strong>. Spanish Government, Ministry of Science and Innovation: CENIT-2009-1026.</p></li><li><p><a href="http://grfia.dlsi.ua.es/cm/projects/drims/"target="_blank"rel="nofollow">DRIMS</a> (2009-2012): <strong>Description and retrieval of music and sound information</strong>. Spanish Government, Ministry of Science and Innovation: TIN-2009-14247-C02-01.</p></li><li><p><a href="http://mtg.upf.edu/project/music3.0"target="_blank"rel="nofollow">Music 3.0</a> (2009-2010): <strong>Integrated system for music creation, interaction and socialization</strong>. Spanish Government, Ministry of Industry, Tourism and Trade: Avanza contenidos, TSI-070100-2008-318.</p></li><li><p><a href="http://www.pharos-audiovisual-search.eu/"target="_blank"rel="nofollow">PHAROS</a> (2007-2009): <strong>Platform for search of audiovisual resources across on-line spaces</strong>. European Commission: IST-2006-045035.</p></li><li><p><a href="http://mtg.upf.edu/research/projects/salero"target="_blank"rel="nofollow">SALERO</a> (2006-2009): <strong>Semantic audiovisual entertainment reusable objects</strong>. European Commission: IST-2007-0309BSCW.</p></li><li><p><a href="http://www.itea-cantata.org/"target="_blank"rel="nofollow">CANTATA</a> (2006-2008): <strong>Content aware networked systems towards advanced and tailored assistance</strong>. European Commission: ITEA-PROFIT, FIT-350205-2007-10.</p></li><li><p><a href="http://emcap.iua.upf.edu/"target="_blank"rel="nofollow">EmCAP</a> (2005-2008): <strong>Emergent cognition through active perception</strong>. European Commission: IST-2006-013123.</p></li></ul></span><p>Privately-funded</p><span style="color: DarkGrey;"><ul><li><p>ARIANA (2018-2019): <strong>Artificial intelligence for automatic network actions</strong>. Telefónica R&#x26;D innovation call.</p></li><li><p><strong><a href="https://www.telefonica.com/web/press-office/-/telefonica-solves-the-attention-economy-challenge-with-smart-notifications"target="_blank"rel="nofollow">Smart Notifications</a></strong> (2016-2018). Telefónica R&#x26;D innovation call.</p></li><li><p><strong>Predictive Health</strong> (2015-2016). Telefónica R&#x26;D moonshot project.</p></li><li><p><a href="http://www.iiia.csic.es/en/project/aisle"target="_blank"rel="nofollow">AISLE</a> (2012): <strong>Artificial intelligence software for logistics in enterprises</strong>. Conzentra Tecnologías de la Información S.L., IIIA-010108120004.</p></li></ul></span><h2 id="merits">Merits<a aria-hidden class="header-link"tabindex="-1"href="#merits">#</a></h2><p>Merits, awards and competitive grants</p><span style="color: DarkGrey;"><ul><li><p><strong>Best student paper nomination</strong> to Santi Pascual for our paper on "Learning problem-agnostic speech representations using multiple self-supervised tasks". <a href="https://www.interspeech2019.org/"target="_blank"rel="nofollow">Conf. of the Int. Speech Comm. Assoc. (INTERSPEECH)</a>, 2019.</p></li><li><p><strong>​Juan de la Cierva Incorporación postdoctoral fellowship</strong> (IJCI-2014-19901; Ranked 1/58). Spanish Government, <a href="https://sede.micinn.gob.es/portal/site/eSede/menuitem.df29f2378d5d10a0cee63510223041a0/?vgnextoid=6767b2f2e31f9410VgnVCM1000001d04140aRCRD&#x26;vgnextfmt=formato1&#x26;lang_choosen=es"target="_blank"rel="nofollow">Spanish Ministry for Economy and Competitiveness</a>, 2015. <em>Declined</em>.</p></li><li><p><strong>Top 1% performer</strong> (Ranked 11/1528) in the <a href="https://www.kaggle.com/c/axa-driver-telematics-analysis/leaderboard"target="_blank"rel="nofollow">Kaggle AXA Driver Telematics Analytics challenge</a>, 2015.</p></li><li><p><strong>Best paper award</strong> for our paper "Cognitive prognosis of acquired brain injury patients using machine learning techniques". <a href="http://www.iaria.org/conferences2013/AwardsCOGNITIVE13.html"target="_blank"rel="nofollow">Int. Conf. on Advanced Cognitive Technologies and Applications (COGNITIVE)</a>, 2013.</p></li><li><p><strong>Best-in-class award</strong> in the 2012 Music Information Retrieval Evaluation eXchange contest (<a href="http://www.music-ir.org/mirex/wiki/2012:MIREX2012_Results"target="_blank"rel="nofollow">MIREX12 Structure Segmentation task</a>).</p></li><li><p><strong>Knowledge transfer award</strong> in the Information and Communication Technologies area (PhD thesis modality). <a href="http://www.upf.edu/consellsocial/"target="_blank"rel="nofollow">Board of Trustees of Universitat Pompeu Fabra</a>, 2011.</p></li><li><p><strong>European doctorate mention</strong>. Universitat Pompeu Fabra, 2011.</p></li><li><p><strong><a href="https://sede.csic.gob.es/servicios/formacion-y-empleo/convocatorias/personal-laboral/2010/jae-doc-2010"target="_blank"rel="nofollow">JAE-DOC postdoctoral grant</a></strong> (JAEDOC069/2010). Consejo Superior de Investigaciones Científicas (CSIC, Spanish National Research Council), 2011-2014.</p></li><li><p><strong>Best-in-class award</strong> in the 2010 Music Information Retrieval Evaluation eXchange contest (<a href="http://nema.lis.uiuc.edu/nema_out/664ccbda-d5b6-48ae-8c47-c27e7c2372fe/results/evaluation/"target="_blank"rel="nofollow">MIREX10 Audio Classical Composer Identification task</a>).</p></li><li><p><strong>One to six month grant</strong> for PhD students and junior researchers (A/09/96235). <a href="http://www.daad.de/"target="_blank"rel="nofollow">Deutscher Akademischer Austausch Dienst</a> (DAAD, German Academic Exchange Service), 2010.</p></li><li><p><strong>Predoctoral scholarship for short research stays abroad</strong> (BE-DGR-2009). Catalan Government, <a href="http://www10.gencat.cat/agaur_web/AppJava/english/index.jsp"target="_blank"rel="nofollow">Agency for Administration of University and Research Grants (AGAUR)</a>, 2010. Declined.</p></li><li><p><strong>Best-in-class award</strong> in the 2009 Music Information Retrieval Evaluation eXchange contest (<a href="http://www.music-ir.org/mirex/2009/index.php/Audio_Cover_Song_Identification_Results"target="_blank"rel="nofollow">MIREX09 Audio Cover Song Identification task</a>).</p></li><li><p><strong>Best-in-class award</strong> in the 2009 Music Information Retrieval Evaluation eXchange contest (<a href="http://www.music-ir.org/mirex/2009/index.php/Audio_Classical_Composer_Identification_Results"target="_blank"rel="nofollow">MIREX09 Audio Classical Composer Identification task</a>).</p></li><li><p><strong>Best-in-class award</strong> in the 2008 Music Information Retrieval Evaluation eXchange contest (<a href="http://www.music-ir.org/mirex/2008/index.php/Audio_Cover_Song_Identification_Results"target="_blank"rel="nofollow">MIREX08 Audio Cover Song Identification task</a>).</p></li><li><p><strong>Best-in-class award</strong> in the 2007 Music Information Retrieval Evaluation eXchange contest (<a href="http://www.music-ir.org/mirex/2007/index.php/Audio_Cover_Song_Identification_Results"target="_blank"rel="nofollow">MIREX07 Audio Cover Song Identification task</a>).</p></li><li><p><strong>​R+D+I scholarship</strong>. Universitat Pompeu Fabra, 2006-2010.</p></li></ul></span><p>Appearances in media <em>[Sorry for the broken links, I promise these all worked at some point]</em></p><span style="color: DarkGrey;"><ul><li><p>An artificial intelligence that does not forget what it learns (2018) --- <a href="https://blogthinkbig.com/inteligencia-artificial-aprende-algoritmo"target="_blank"rel="nofollow">BlogThinkBig</a>, <a href="https://www.techworld.com/tech-innovation/what-is-catastrophic-forgetting-how-does-it-affect-ai-development-3687007/"target="_blank"rel="nofollow">TechWorld News</a>.</p></li><li><p>Just four tweets can reveal the identity of an anonymous troll (2018) ---<a href="https://www.newscientist.com/article/2172243-just-four-tweets-can-reveal-the-identity-of-an-anonymous-troll/"target="_blank"rel="nofollow">New Scientist</a>, <a href="https://cacm.acm.org/news/229013-4-tweets-can-reveal-the-identity-of-an-anonymous-troll/fulltext"target="_blank"rel="nofollow">Comm. of the ACM.</a></p></li><li><p>​¡Sistemas de recomendación en forma! (2018) --- <a href="https://blogthinkbig.com/sistemas-de-recomendacion-en-forma"target="_blank"rel="nofollow">BlogThinkBig</a>.</p></li><li><p>Note onset deviations as musical piece signatures (2013) --- <a href="http://www.iiia.csic.es/%7Ejserra/misc/ara_131215.pdf"target="_blank"rel="nofollow">Diari Ara</a>.</p></li><li><p>The computer as music critic (2012) --- <a href="http://www.nytimes.com/2012/09/16/opinion/sunday/the-computer-as-music-critic.html"target="_blank"rel="nofollow">NYTimes</a>, <a href="http://www.acia.org/nodes/modules.php?name=news&#x26;idnew=96"target="_blank"rel="nofollow">ACIA Nodes</a>.</p></li><li><p>Measuring the evolution of contemporary western popular music (2012) --- <a href="http://www.iiia.csic.es/%7Ejserra/misc/media_natureasia.pdf"target="_blank"rel="nofollow">Nature Asia</a>, <a href="http://www.rtve.es/alacarta/videos/telediario/telediario-15-horas-30-07-12/1494552/"target="_blank"rel="nofollow">TVE (Informativos, min 42:30)</a>, <a href="http://www.antena3.com/videos/completos-noticias1/2012-julio-30-2012073000025.html"target="_blank"rel="nofollow">Antena3 (Telediario, part 3, min 3:40)</a>, <a href="http://www.iiia.csic.es/%7Ejserra/misc/lavanguardia_120727.pdf"target="_blank"rel="nofollow">La Vanguardia</a>, <a href="http://cultura.elpais.com/cultura/2012/07/27/actualidad/1343409481_440570.html"target="_blank"rel="nofollow">El País</a>, <a href="http://blogs.scientificamerican.com/observations/2012/07/26/is-pop-music-evolving-or-is-it-just-getting-louder/"target="_blank"rel="nofollow">Scientific American</a>, <a href="http://www.economist.com/blogs/babbage/2012/07/science-music"target="_blank"rel="nofollow">The Economist (Babbage)</a>, <a href="http://www.reuters.com/article/2012/07/26/us-science-music-idUSBRE86P0R820120726"target="_blank"rel="nofollow">Reuters</a>, <a href="http://news.cnet.com/8301-17852_3-57480692-71/the-songs-remain-the-same-but-louder-say-scientists/"target="_blank"rel="nofollow">CNet</a>, <a href="http://www.guardian.co.uk/music/2012/jul/27/pop-music-sounds-same-survey-reveals"target="_blank"rel="nofollow">The Guardian</a>, <a href="http://www.dailymail.co.uk/sciencetech/article-2179432/All-songs-DO-sound-Modern-pop-louder-uses-chords-classic-albums-Fifties-Sixties.html"target="_blank"rel="nofollow">Daily Mail</a>, <a href="http://www.telegraph.co.uk/culture/music/9430338/Modern-music-really-does-sound-the-same.html"target="_blank"rel="nofollow">The Telegraph</a>, ... Also highlighted in <a href="http://www.iiia.csic.es/%7Ejserra/misc/media_nature.png"target="_blank"rel="nofollow">Nature.com</a>.</p></li><li><p>Identification of versions of the same musical composition by processing audio descriptions (2011) --- <a href="http://www.upf.edu/enoticies-recerca/1011/0418.html"target="_blank"rel="nofollow">UPF e-Notícies</a>.</p></li><li><p>MTG Technology (2010) --- <a href="http://www.rtve.es/alacarta/todos/ultimos/index.html#688418"target="_blank"rel="nofollow">TVE (Tres 14, min 19)</a>.</p></li><li><p>Unsupervised detection of cover song sets: accuracy improvement and original identification (2010) --- <a href="http://www.upf.edu/enoticies-recerca/0910/1017.html"target="_blank"rel="nofollow">UPF e-Notícies</a>.</p></li><li><p>Cross recurrence quantification for cover song identification (2009) --- <a href="http://blocs.lamalla.cat/bloc/extraradi/post/plagis_musicals"target="_blank"rel="nofollow">COM Radio (Extraradi)</a>, <a href="http://www.abc.es/20091021/ciencia-tecnologia-matematicas/esta-cancion-fraude-200910211148.html"target="_blank"rel="nofollow">Diario ABC</a>, <a href="http://www.sciencedaily.com/releases/2009/10/091022101549.htm"target="_blank"rel="nofollow">Science Daily</a>, <a href="http://www.innovations-report.com/html/reports/physics_astronomy/a_technique_identifies_versions_song_142216.html"target="_blank"rel="nofollow">Innovations-report</a>, <a href="http://www.physorg.com/news175425825.html"target="_blank"rel="nofollow">PhysOrg</a>, <a href="http://plataformasinc.es/index.php/esl/Noticias/Una-nueva-tecnica-identifica-versiones-de-una-misma-cancion"target="_blank"rel="nofollow">SINC</a>, <a href="http://www.thefreelibrary.com/Technique+that+identifies+versions+of+the+same+song+developed.-a0210561185"target="_blank"rel="nofollow">Asian News Int.</a>, ...</p></li></ul></span><h2 id="teaching">Teaching<a aria-hidden class="header-link"tabindex="-1"href="#teaching">#</a></h2><p><em>[Currently I'm not teaching]</em></p><span style="color: DarkGrey;"><ul><li><p><strong>Invited lecturer</strong>, Universitat de Vic, Vic, Barcelona (2020). Postgraduate course on Artificial Intelligence with Deep Learning (2019-2020), Universitat Politècnica de Catalunya, Barcelona. Master in Sound and Music Computing (2019), Universitat Pompeu Fabra, Barcelona --- Deep learning seminars, theory, applications, &#x26; coding.</p></li><li><p><strong>Part-time adjunct professor</strong>, Universitat de Vic, Vic, Barcelona. Undergraduate studies of Biomedical Engineering. Diagnosis Decision Support Systems: Deep learning seminars &#x26; coding (2018-2019).</p></li><li><p><strong><a href="http://www.aqu.cat/professorat/lector/index_en.html"target="_blank"rel="nofollow">Tenure-track lecturer accreditation</a></strong> ("Professor Lector") from the Catalan Government (Agency for Management of University and Research Grants, <a href="http://www.gencat.cat/agaur/"target="_blank"rel="nofollow">AGAUR</a>), Jan 2014.</p></li><li><p><strong>Teaching assistant</strong>, Dept. of Inf. and Com. Tech., Universitat Pompeu Fabra, Barcelona. Undergraduate studies. Probabilitat i processos estocàstics (2010-2011), càlcul mètodes numèrics (2009-2010), fonaments físics de la informàtica (2008-2010), computadors III (2006-2009).</p></li><li><p><strong>​Invited instructor</strong>, Eng. La Salle, Universitat Ramon Llull, Barcelona. MSc studies. Máster de Producción Sonora y Audio Digital. Music information retrieval (2007-2008).</p></li></ul></span><h2 id="studentsinterns">Students/interns<a aria-hidden class="header-link"tabindex="-1"href="#studentsinterns">#</a></h2><span style="color: DarkGrey;"><ul><li><p><strong>R.O. Araz</strong>. <em>Improving quality and speed of universal speech enhancement with diffusion models</em>. Student internship, Dolby Laboratories. Ongoing.</p></li><li><p><strong>F. Yesiler</strong>. <em>Data-driven musical version identification: accuracy, scalability, and bias perspectives</em>. PhD thesis, Universitat Pompeu Fabra. 2018-Ongoing. Co-directed with E. Gómez.</p></li><li><p><strong>G. Cambara</strong>. <em>The effect of regressive and discriminative workers for learning self-supervised speech representations</em>. Student internship, Dolby Laboratories. Sep 2021. Co-directed with S. Pascual.</p></li><li><p><strong>J. Bustos</strong>. <em>Towards audio-conditioned generation of music album artwork</em>. MSc thesis, Universitat Pompeu Fabra. Sep 2020. Co-directed with P. Herrera.</p></li><li><p><strong>C. Steinmetz</strong>. <em>Learning to mix with neural audio effects in the waveform domain</em>. MSc thesis, Universitat Pompeu Fabra, &#x26; Student internship, Dolby Laboratories. Sep 2020. Co-directed with F. Font.</p></li><li><p><strong>S. Pascual</strong>. <em>End-to-end speech synthesis using deep neural networks</em>. PhD thesis, Universitat Politècnica de Catalunya. 2017-2020. Co-directed with A. Bonafonte.</p></li><li><p><strong>M. Serra-Peralta</strong>. <em>Tunable, flow-based recommendations</em>. Student internship, Telefónica Research. Dec 2019. Co-directed with C. Segura.</p></li><li><p><strong>D. Álvarez</strong>. <em>Out-of-distribution likelihoods in deep generative models</em>. Student internship, Telefónica Research. Nov 2019.</p></li><li><p><strong>M. Carós</strong>. <em>Deep anomaly detection in machine-to-machine network logs</em>. Student internship, Telefónica Research. Jul 2019. Co-directed with A. Lutu &#x26; D. Perino.</p></li><li><p><strong>A. Gilbert</strong>. <em>An investigation of in-sample forgetting in deep convolutional neural networks</em>. MSc thesis, Universitat Pompeu Fabra. Jul 2019. Co-directed with M. Farrús.</p></li><li><p><strong>J.F. Núñez</strong>. <em>Normalizing flows for novelty detection</em>. MSc thesis, Universitat Pompeu Fabra. Jul 2019. Co-directed with V. Gómez.</p></li><li><p><strong>O. Slizovskaya</strong>. <em>A prospective study of time series anomaly detection with normalizing flows</em>. Student internship, Telefónica Research. Dec 2018. Co-directed with I. Leontiadis.</p></li><li><p><strong>M. del Tredici</strong>. <em>Graph convolutional networks for recommender systems</em>. Student internship, Telefónica Research. Oct 2018. Co-directed with A. Karatzoglou, J. Luque, &#x26; C. Segura.</p></li><li><p><strong>S. Raponi</strong>. <em>User anonymity and reidentification in mobile weblog traces</em>. Student internship, Telefónica Research. Aug 2018. Co-directed with N. Kourtellis, I. Leontiadis, &#x26; D. Perino.</p></li><li><p><strong>J. Pons</strong>. <em>Neural network architectures for few-instance audio classification</em>. Student internship, Telefónica Research. Jul 2018.</p></li><li><p><strong>D. Surís &#x26; M. Miron</strong>. <em>Overcoming catastrophic forgetting in neural networks</em>. Student internships, Telefónica Research. Dec 2017.</p></li><li><p><strong>A. Pyrgelis</strong>. <em>Assessing mobility trajectory uniqueness in telco networks</em>. Student internship, Telefónica Research. Nov 2017. Co-directed with I. Leontiadis, N. Kourtellis, &#x26; C. Soriente.</p></li><li><p><strong>S. Pascual</strong>. <em>Deep spatiotemporal mobility prediction from cellular network events</em>. Student internship, Telefónica Research. Dec 2016.</p></li><li><p><strong>M.A. Orakzai</strong>. <em>Gait-based authentication in real life</em>. MSc thesis, Universitat Politècnica de Catalunya. Student internship, Telefónica Research. Jul 2016. Co-directed with A. Matic, L. Navarro, &#x26; C. Soriente.</p></li><li><p><strong>G. Pelino &#x26; Z. Holler</strong>. <em>Predicting the success of telemarketing campaign calls</em>. MSc thesis, Barcelona Graduate School of Economics. Student internships, Telefónica Research. Jul 2016. Co-directed with A. Karatzoglou &#x26; A. Matic.</p></li><li><p><strong>J.C. Vásquez-Correa</strong>. <em>Analyzing the robustness of speech-based Parkinson detection algorithms under noise and audio transformations</em>. Student internship, Telefónica Research. Feb 2016.</p></li><li><p><strong>A. Bogomolov</strong>. <em>Using call detail records for understanding crime data</em>. Student internship, Telefónica Research. Jan 2016. Co-directed with N. Oliver.</p></li><li><p><strong>F. Capó</strong>. <em>Western classical composer identification using symbolic data</em>. MSc thesis, Universitat Pompeu Fabra. Sep 2015. Co-directed with P. Herrera.</p></li><li><p><strong>F. Font</strong>. <em>Tag recommendation using folksonomy information for online sound sharing platforms</em>. PhD thesis, Universitat Pompeu Fabra. Jun 2015. Co-directed with X. Serra.</p></li><li><p><strong>G. Herrero</strong>. <em>Towards supervised music structure annotation: a case-based fusion approach</em>. MSc thesis, Universitat Pompeu Fabra. Sep 2014.</p></li><li><p><strong>M. Carbonell</strong>. <em>Power laws: from linguistics to music</em>. Bachelor's final project, Universitat Autònoma de Barcelona. Feb 2014. Co-directed with A. Corral.</p></li><li><p><strong>G. Meseguer</strong>. <em>Automatic content-based detection of influences in the history of progressive rock music</em>. MSc thesis, Universitat Pompeu Fabra. Sep 2013. Co-directed with P. Herrera.</p></li><li><p><strong>J. Van Balen</strong>. <em>Automatic recognition of samples in musical audio</em>. MSc thesis, Universitat Pompeu Fabra. Sep 2011. Co-directed with M. Haro.</p></li><li><p><strong>C. A. De Los Santos</strong>. <em>Nonlinear audio recurrence analysis with application to music genre classification</em>. MSc thesis, Universitat Pompeu Fabra. Sep 2010. Co-directed with R. G. Andrzejak.</p></li><li><p><strong>S. Bromberg</strong>. <em>Recurrence quantification analysis in music information retrieval tasks: an example on genre classification</em>. MSc thesis, Universitat Pompeu Fabra. Jun 2010. Co-directed with R. G. Andrzejak.</p></li><li><p><strong>A. Almarza</strong>. <em>Implementació i avaluació d’algorismes per la descripció i classificació rítmica de la música</em>. Bachelor's final project, Universitat de Girona. Apr 2010.</p></li><li><p><strong>​C. Quirante</strong>. <em>Quality assessment and enhancement of an industrial-strength audio fingerprinting system</em>. MSc thesis, Universitat Pompeu Fabra. Sep 2009. Co-directed with P. Cano.</p></li></ul></span><h1 id="contact">Contact<a aria-hidden class="header-link"tabindex="-1"href="#contact">#</a></h1><span style="color: DarkGrey;"><blockquote><p>Joan Serrà<br>Dolby Laboratories<br>Av. Diagonal 177, Planta 10<br>08018 Barcelona<br>firstname (dot) serra (at) dolby (dot) com<br></p></blockquote></span><br><iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2992.6061449347076!2d2.1916310163261206!3d41.404358979262405!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x12a4a32345143ac1%3A0x24ee709ab0dfc633!2sAvinguda%20Diagonal%2C%20177%2C%2008018%20Barcelona!5e0!3m2!1sen!2ses!4v1572971804008!5m2!1sen!2ses"style="border:0;"allowfullscreen=""width="600"height="450"frameborder="0"></iframe></div></main><div class="top-bar"data-js="top-bar"><button class="top-bar__menu-toggle-button"data-js="top-bar-menu-toggle-button"><svg class="top-bar__menu-toggle-button-menu-svg"viewBox="0 0 16 16"xmlns="http://www.w3.org/2000/svg"><path fill="currentColor"fill-rule="evenodd"clip-rule="evenodd"d="M0 2.75C0 2.33579.335786 2 .75 2h14.5c.4142 0 .75.33579.75.75s-.3358.75-.75.75H.75C.335786 3.5 0 3.16421 0 2.75zM0 8c0-.41421.335786-.75.75-.75h14.5c.4142 0 .75.33579.75.75s-.3358.75-.75.75H.75C.335786 8.75 0 8.41421 0 8zm.75 4.5c-.414214 0-.75.3358-.75.75s.335786.75.75.75h14.5c.4142 0 .75-.3358.75-.75s-.3358-.75-.75-.75H.75z"/></svg> <svg class="top-bar__menu-toggle-button-close-svg"viewBox="0 0 16 16"xmlns="http://www.w3.org/2000/svg"><path fill="currentColor"fill-rule="evenodd"clip-rule="evenodd"d="M1.28033.21967c-.292893-.2928933-.767767-.2928933-1.06066 0-.2928933.292893-.2928933.767767 0 1.06066L6.93934 8 .21967 14.7197c-.2928933.2929-.2928933.7677 0 1.0606.292893.2929.767767.2929 1.06066 0L8 9.06066l6.7197 6.71964c.2929.2929.7677.2929 1.0606 0 .2929-.2929.2929-.7677 0-1.0606L9.06066 8l6.71964-6.71967c.2929-.292893.2929-.767767 0-1.06066-.2929-.2928933-.7677-.2928933-1.0606 0L8 6.93934 1.28033.21967z"/></svg></button><div class="top-bar__title"><a class="top-bar__title-link"href="https://serrjoa.github.io/"data-js="top-bar-title-link">Joan Serrà</a></div><div class="top-bar__items"><ul><li><a href="#short-bio">Short bio</a></li><li><a href="#publications">Publications</a></li><li><a href="#talks">Talks</a></li><li><a href="#misc">Misc</a></li><li><a href="#contact">Contact</a></li></ul></div></div><div class="menu"data-js="menu"><ul><li><a href="#short-bio">Short bio</a></li><li><a href="#publications">Publications</a><ul><li><a href="#ongoing">Ongoing</a></li><li><a href="#recent-2021-2022">Recent (2021-2022)</a></li><li><a href="#past-2011-2020">Past (2011-2020)</a></li><li><a href="#prehistoric-2007-2010">Prehistoric (2007-2010)</a></li></ul></li><li><a href="#talks">Talks</a></li><li><a href="#misc">Misc</a><ul><li><a href="#experienceeducation">Experience/education</a></li><li><a href="#scientific-service">Scientific service</a></li><li><a href="#projects">Projects</a></li><li><a href="#merits">Merits</a></li><li><a href="#teaching">Teaching</a></li><li><a href="#studentsinterns">Students/interns</a></li></ul></li><li><a href="#contact">Contact</a></li></ul></div><script>(()=>{"use strict";function t(t,e){for(;null!==t&&!0!==e(t);)t=t.parentElement;return t}function e(t){const{activeClassName:e,contentElement:o,menuElement:i,scrollMarginTopOffset:l,topBarElement:r}=t;function c(){return Array.prototype.slice.call(o.querySelectorAll("[id]"))}function u(){const t=c(),e=t[t.length-1],n=window.innerHeight-(r.offsetHeight+l)-(o.offsetHeight-e.offsetTop);n<0?o.removeAttribute("style"):o.style.paddingBottom=`${n}px`}let s;u(),window.addEventListener("resize",(function(){window.clearTimeout(s),s=window.setTimeout((function(){u()}),200)})),window.addEventListener("scroll",(function(){const t=c(),o=function(t){const{idElements:e,scrollMarginTop:n}=t,o=e.slice().reverse(),i=window.scrollY;for(const t of o)if(t.offsetTop-n-2<=i)return t.getAttribute("id");return null}({idElements:t,scrollMarginTop:r.offsetHeight+l});n({activeClassName:e,element:i,id:o});const u=function(t){const{activeId:e,idElements:n}=t;if(null===e)return null;const o=n.findIndex((function(t){return t.getAttribute("id")===e})),i=n.slice(0,o+1).reverse().find((function(t){return"H1"===t.tagName}));if(void 0!==i)return i.getAttribute("id");const l=n.find((function(t){return"H1"===t.tagName}));if(void 0===l)return null;return l.getAttribute("id")}({activeId:o,idElements:t});n({activeClassName:e,element:r,id:u})}))}function n(t){const{element:e,id:n,activeClassName:o}=t,i=e.querySelector(`.${o}`);if(null!==i&&i.classList.remove(o),null===n)return;const l=e.querySelector(`[href="#${null===n?"":n}"]`);null!==l&&l.classList.add(o)}!function(){const n=document.querySelector('[data-js="content"]'),o=document.querySelector('[data-js="top-bar"]'),i=document.querySelector('[data-js="top-bar-menu-toggle-button"]'),l=document.querySelector('[data-js="top-bar-title-link"]'),r=document.querySelector('[data-js="menu"]');null!==i&&function(e){const{breakpoint:n,topBarMenuToggleButtonElement:o,visibleClassName:i}=e;function l(){document.body.classList.toggle(i)}o.addEventListener("click",l),window.addEventListener("click",(function(e){!1!==document.body.classList.contains(i)&&(window.innerWidth>=n||null===t(e.target,(function(t){return t===o}))&&l())})),window.addEventListener("keydown",(function(t){"Escape"===t.key&&l()}))}({breakpoint:1600,topBarMenuToggleButtonElement:i,visibleClassName:"--menu-visible"}),null!==r&&null!==l&&function(t){const{topBarTitleLinkElement:e,menuElement:n}=t;e.addEventListener("click",(function(t){!0!==t.metaKey&&!0!==t.shiftKey&&(t.preventDefault(),history.pushState("",document.title,`${window.location.pathname}${window.location.search}`),window.scrollTo({top:0}),n.scrollTo({top:0}))}))}({menuElement:r,topBarTitleLinkElement:l}),null!==r&&function(e,n){function o(t){const o=e.querySelector(`[href="${t}"]`);if(null===o)return;const i=o.getBoundingClientRect(),l=null===n?0:n.offsetHeight,r=window.innerHeight;if(i.top>=l&&i.bottom<=r)return;const c=1*window.parseFloat(window.getComputedStyle(document.documentElement).fontSize);e.scrollTo({top:Math.max(0,o.offsetTop-c)})}function i(){const t=window.location.hash;""!==t?o(t):e.scrollTo({top:0})}window.addEventListener("click",(function(n){const i=n.target;if("A"!==i.tagName)return;const l=i.getAttribute("href");null!==l&&null===t(i,(function(t){return t===e}))&&o(l)})),window.addEventListener("popstate",i),i()}(r,o),null!==r&&null!==n&&null!==o&&e({activeClassName:"--scroll-spy-active",contentElement:n,menuElement:r,scrollMarginTopOffset:40,topBarElement:o})}()})();</script></body></html>